{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {},
   "source": [
    "# Lesson 12: Course Review & Final Project Launch\n",
    "\n",
    "**Session:** Week 3, Sunday (3 hours)  \n",
    "**Learning Objectives:**\n",
    "- Consolidate and review all Python fundamentals learned\n",
    "- Demonstrate mastery through comprehensive exercises\n",
    "- Launch the capstone final project\n",
    "- Plan next steps in your data science journey\n",
    "- Celebrate your incredible transformation from beginner to data scientist!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "celebration",
   "metadata": {},
   "source": [
    "## 🎉 Welcome to Your Final Class!\n",
    "\n",
    "**Congratulations! You've completed an incredible journey:**\n",
    "\n",
    "### 📈 Your Transformation\n",
    "- **3 weeks ago**: Complete Python beginners\n",
    "- **Today**: Confident data scientists who can build complete analysis systems!\n",
    "\n",
    "### 🎯 What You've Mastered\n",
    "- **Week 1**: Python foundations (variables, data types, strings, lists, dictionaries)\n",
    "- **Week 2**: Program logic (conditionals, loops, functions, code organization) \n",
    "- **Week 3**: Real-world skills (file I/O, error handling, data analysis, project development)\n",
    "\n",
    "### 🏆 What Makes You Special\n",
    "Unlike many Python courses that focus only on syntax, you've learned:\n",
    "- **Problem-solving thinking** - How to break down complex challenges\n",
    "- **Data intuition** - How to find insights in messy, real-world data\n",
    "- **Professional practices** - Error handling, testing, and documentation\n",
    "- **Business communication** - Translating technical work into actionable insights\n",
    "\n",
    "**Today we review, consolidate, and launch your final capstone project!** 🚀"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "course_review",
   "metadata": {},
   "source": [
    "## 📚 Complete Course Review\n",
    "\n",
    "Let's systematically review everything you've learned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "week1_review",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WEEK 1 FUNDAMENTALS REVIEW\n",
    "print(\"📊 WEEK 1: PYTHON FUNDAMENTALS REVIEW\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. Variables and Data Types\n",
    "print(\"\\n🏗️ VARIABLES & DATA TYPES:\")\n",
    "\n",
    "# Basic data types\n",
    "name = \"Data Scientist\"  # String\n",
    "age = 25                 # Integer\n",
    "salary = 85000.50        # Float\n",
    "is_employed = True       # Boolean\n",
    "skills = None           # NoneType\n",
    "\n",
    "print(f\"Name: {name} (type: {type(name).__name__})\")\n",
    "print(f\"Age: {age} (type: {type(age).__name__})\")\n",
    "print(f\"Salary: ${salary:,.2f} (type: {type(salary).__name__})\")\n",
    "print(f\"Employed: {is_employed} (type: {type(is_employed).__name__})\")\n",
    "print(f\"Skills: {skills} (type: {type(skills).__name__})\")\n",
    "\n",
    "# Type conversion mastery\n",
    "print(\"\\n🔄 TYPE CONVERSION MASTERY:\")\n",
    "score_str = \"95\"\n",
    "score_int = int(score_str)\n",
    "score_float = float(score_str)\n",
    "print(f\"String '{score_str}' → int: {score_int}, float: {score_float}\")\n",
    "\n",
    "# 2. String Operations\n",
    "print(\"\\n📝 STRING OPERATIONS:\")\n",
    "message = \"  Python Data Science  \"\n",
    "print(f\"Original: '{message}'\")\n",
    "print(f\"Cleaned: '{message.strip().lower()}'\")\n",
    "print(f\"Title case: '{message.strip().title()}'\")\n",
    "print(f\"Contains 'data': {'data' in message.lower()}\")\n",
    "print(f\"Word count: {len(message.split())}\")\n",
    "\n",
    "# F-strings mastery\n",
    "first_name = \"Alice\"\n",
    "last_name = \"Johnson\"\n",
    "score = 94.7\n",
    "print(f\"\\nF-string mastery: {first_name} {last_name} scored {score:.1f}%\")\n",
    "print(f\"Formatted: {score:08.2f} (padded with zeros)\")\n",
    "\n",
    "print(\"\\n✅ Week 1 fundamentals: MASTERED!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "week1_data_structures",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WEEK 1 DATA STRUCTURES REVIEW\n",
    "print(\"\\n📊 WEEK 1: DATA STRUCTURES REVIEW\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 3. Lists Mastery\n",
    "print(\"\\n📋 LISTS MASTERY:\")\n",
    "students = ['Alice', 'Bob', 'Charlie', 'Diana']\n",
    "grades = [95, 87, 92, 89]\n",
    "\n",
    "# List operations\n",
    "print(f\"Students: {students}\")\n",
    "print(f\"Grades: {grades}\")\n",
    "print(f\"First student: {students[0]}, Last grade: {grades[-1]}\")\n",
    "print(f\"Top 2 students: {students[:2]}\")\n",
    "print(f\"Average grade: {sum(grades)/len(grades):.1f}\")\n",
    "\n",
    "# List methods\n",
    "new_students = students.copy()\n",
    "new_students.append('Eve')\n",
    "new_students.insert(1, 'Frank')\n",
    "print(f\"Updated list: {new_students}\")\n",
    "print(f\"Bob's position: {new_students.index('Bob')}\")\n",
    "\n",
    "# List comprehension preview\n",
    "high_grades = [grade for grade in grades if grade >= 90]\n",
    "print(f\"High grades (≥90): {high_grades}\")\n",
    "\n",
    "# 4. Dictionaries Mastery\n",
    "print(\"\\n🗃️ DICTIONARIES MASTERY:\")\n",
    "student_data = {\n",
    "    'name': 'Alice Johnson',\n",
    "    'age': 22,\n",
    "    'major': 'Data Science',\n",
    "    'grades': [95, 88, 92, 90],\n",
    "    'contact': {\n",
    "        'email': 'alice@university.edu',\n",
    "        'phone': '555-0123'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Dictionary operations\n",
    "print(f\"Student: {student_data['name']}\")\n",
    "print(f\"Email: {student_data['contact']['email']}\")\n",
    "print(f\"Average grade: {sum(student_data['grades'])/len(student_data['grades']):.1f}\")\n",
    "\n",
    "# Dictionary methods\n",
    "print(f\"\\nAll keys: {list(student_data.keys())}\")\n",
    "print(f\"Has phone: {'phone' in student_data['contact']}\")\n",
    "\n",
    "# Adding new data\n",
    "student_data['gpa'] = 3.85\n",
    "student_data['skills'] = ['Python', 'SQL', 'Statistics']\n",
    "print(f\"Updated student data keys: {list(student_data.keys())}\")\n",
    "\n",
    "# 5. Sets (bonus)\n",
    "print(\"\\n🎯 SETS (BONUS):\")\n",
    "python_students = {'Alice', 'Bob', 'Charlie', 'Diana'}\n",
    "sql_students = {'Bob', 'Diana', 'Eve', 'Frank'}\n",
    "\n",
    "print(f\"Python students: {python_students}\")\n",
    "print(f\"SQL students: {sql_students}\")\n",
    "print(f\"Both skills: {python_students & sql_students}\")\n",
    "print(f\"Any skill: {python_students | sql_students}\")\n",
    "print(f\"Python only: {python_students - sql_students}\")\n",
    "\n",
    "print(\"\\n✅ Week 1 data structures: MASTERED!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "week2_review",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WEEK 2 PROGRAM LOGIC REVIEW\n",
    "print(\"\\n🧠 WEEK 2: PROGRAM LOGIC REVIEW\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 6. Conditionals Mastery\n",
    "print(\"\\n🚦 CONDITIONALS MASTERY:\")\n",
    "\n",
    "def evaluate_student(name, grade, attendance):\n",
    "    \"\"\"Comprehensive student evaluation using conditionals\"\"\"\n",
    "    \n",
    "    # Grade evaluation\n",
    "    if grade >= 95:\n",
    "        grade_level = \"Exceptional\"\n",
    "        letter = \"A+\"\n",
    "    elif grade >= 90:\n",
    "        grade_level = \"Excellent\"\n",
    "        letter = \"A\"\n",
    "    elif grade >= 80:\n",
    "        grade_level = \"Good\"\n",
    "        letter = \"B\"\n",
    "    elif grade >= 70:\n",
    "        grade_level = \"Satisfactory\"\n",
    "        letter = \"C\"\n",
    "    else:\n",
    "        grade_level = \"Needs Improvement\"\n",
    "        letter = \"F\"\n",
    "    \n",
    "    # Attendance evaluation\n",
    "    if attendance >= 95:\n",
    "        attendance_status = \"Perfect\"\n",
    "    elif attendance >= 85:\n",
    "        attendance_status = \"Good\"\n",
    "    else:\n",
    "        attendance_status = \"Concerning\"\n",
    "    \n",
    "    # Combined evaluation with complex conditions\n",
    "    if grade >= 90 and attendance >= 90:\n",
    "        overall_status = \"Dean's List\"\n",
    "    elif grade >= 80 and attendance >= 80:\n",
    "        overall_status = \"Good Standing\"\n",
    "    elif grade < 70 or attendance < 75:\n",
    "        overall_status = \"Academic Probation\"\n",
    "    else:\n",
    "        overall_status = \"Satisfactory\"\n",
    "    \n",
    "    return {\n",
    "        'name': name,\n",
    "        'grade': grade,\n",
    "        'letter': letter,\n",
    "        'grade_level': grade_level,\n",
    "        'attendance': attendance,\n",
    "        'attendance_status': attendance_status,\n",
    "        'overall_status': overall_status\n",
    "    }\n",
    "\n",
    "# Test conditional logic\n",
    "test_students = [\n",
    "    ('Alice', 96, 98),\n",
    "    ('Bob', 78, 85),\n",
    "    ('Charlie', 65, 70)\n",
    "]\n",
    "\n",
    "for name, grade, attendance in test_students:\n",
    "    result = evaluate_student(name, grade, attendance)\n",
    "    print(f\"{result['name']}: {result['letter']} ({result['grade']}%), {result['attendance']}% attendance → {result['overall_status']}\")\n",
    "\n",
    "print(\"\\n✅ Conditionals mastery: Complex decision-making achieved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "week2_loops",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WEEK 2 LOOPS REVIEW\n",
    "print(\"\\n🔄 WEEK 2: LOOPS MASTERY REVIEW\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 7. For Loops Mastery\n",
    "print(\"\\n🔁 FOR LOOPS MASTERY:\")\n",
    "\n",
    "# Sales data for analysis\n",
    "sales_data = [\n",
    "    {'product': 'Laptop', 'price': 999.99, 'quantity': 5, 'category': 'Electronics'},\n",
    "    {'product': 'Mouse', 'price': 29.99, 'quantity': 15, 'category': 'Electronics'},\n",
    "    {'product': 'Book', 'price': 19.99, 'quantity': 8, 'category': 'Education'},\n",
    "    {'product': 'Desk', 'price': 299.99, 'quantity': 3, 'category': 'Furniture'},\n",
    "]\n",
    "\n",
    "# Pattern 1: Accumulator pattern\n",
    "total_revenue = 0\n",
    "total_items = 0\n",
    "\n",
    "for item in sales_data:\n",
    "    item_revenue = item['price'] * item['quantity']\n",
    "    total_revenue += item_revenue\n",
    "    total_items += item['quantity']\n",
    "    print(f\"{item['product']}: ${item_revenue:,.2f} revenue ({item['quantity']} units)\")\n",
    "\n",
    "print(f\"\\nTotal Revenue: ${total_revenue:,.2f}\")\n",
    "print(f\"Total Items Sold: {total_items}\")\n",
    "print(f\"Average Order Value: ${total_revenue/len(sales_data):,.2f}\")\n",
    "\n",
    "# Pattern 2: Grouping pattern\n",
    "categories = {}\n",
    "for item in sales_data:\n",
    "    category = item['category']\n",
    "    if category not in categories:\n",
    "        categories[category] = {'revenue': 0, 'items': 0}\n",
    "    \n",
    "    categories[category]['revenue'] += item['price'] * item['quantity']\n",
    "    categories[category]['items'] += item['quantity']\n",
    "\n",
    "print(\"\\nRevenue by Category:\")\n",
    "for category, stats in categories.items():\n",
    "    print(f\"{category}: ${stats['revenue']:,.2f} ({stats['items']} items)\")\n",
    "\n",
    "# Pattern 3: Nested loops for comparison\n",
    "print(\"\\nPrice Comparison Matrix:\")\nfor i, item1 in enumerate(sales_data):\n",
    "    for j, item2 in enumerate(sales_data):\n",
    "        if i < j:  # Avoid duplicate comparisons\n",
    "            price_diff = abs(item1['price'] - item2['price'])\n",
    "            print(f\"{item1['product']} vs {item2['product']}: ${price_diff:.2f} difference\")\n",
    "\n",
    "print(\"\\n✅ For loops mastery: Complex data processing achieved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "week2_functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WEEK 2 FUNCTIONS REVIEW\n",
    "print(\"\\n⚙️ WEEK 2: FUNCTIONS MASTERY REVIEW\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 8. Functions Mastery\n",
    "print(\"\\n🔧 FUNCTIONS MASTERY:\")\n",
    "\n",
    "# Basic function with parameters and return\n",
    "def calculate_grade_stats(grades):\n",
    "    \"\"\"\n",
    "    Calculate comprehensive statistics for a list of grades\n",
    "    \n",
    "    Args:\n",
    "        grades (list): List of numeric grades\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary containing grade statistics\n",
    "    \"\"\"\n",
    "    if not grades:\n",
    "        return None\n",
    "    \n",
    "    stats = {\n",
    "        'count': len(grades),\n",
    "        'average': sum(grades) / len(grades),\n",
    "        'highest': max(grades),\n",
    "        'lowest': min(grades),\n",
    "        'passing_count': sum(1 for grade in grades if grade >= 70)\n",
    "    }\n",
    "    \n",
    "    stats['passing_rate'] = (stats['passing_count'] / stats['count']) * 100\n",
    "    stats['range'] = stats['highest'] - stats['lowest']\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# Function with default parameters\n",
    "def format_grade_report(student_name, grade, attendance=100, extra_credit=0):\n",
    "    \"\"\"\n",
    "    Format a comprehensive grade report\n",
    "    \n",
    "    Args:\n",
    "        student_name (str): Student's name\n",
    "        grade (float): Base grade\n",
    "        attendance (float, optional): Attendance percentage. Defaults to 100.\n",
    "        extra_credit (float, optional): Extra credit points. Defaults to 0.\n",
    "    \n",
    "    Returns:\n",
    "        str: Formatted grade report\n",
    "    \"\"\"\n",
    "    final_grade = min(100, grade + extra_credit)\n",
    "    \n",
    "    # Attendance adjustment\n",
    "    if attendance < 80:\n",
    "        final_grade *= 0.95  # 5% penalty for poor attendance\n",
    "    \n",
    "    report = f\"\"\"\n",
    "    GRADE REPORT FOR {student_name.upper()}\n",
    "    ================================\n",
    "    Base Grade: {grade}%\n",
    "    Extra Credit: +{extra_credit}%\n",
    "    Attendance: {attendance}%\n",
    "    Final Grade: {final_grade:.1f}%\n",
    "    Status: {'PASS' if final_grade >= 70 else 'FAIL'}\n",
    "    \"\"\"\n",
    "    \n",
    "    return report.strip()\n",
    "\n",
    "# Function with *args and **kwargs\n",
    "def analyze_multiple_classes(*class_grades, **options):\n",
    "    \"\"\"\n",
    "    Analyze grades across multiple classes\n",
    "    \n",
    "    Args:\n",
    "        *class_grades: Variable number of grade lists\n",
    "        **options: Optional parameters (show_details, min_passing_grade)\n",
    "    \n",
    "    Returns:\n",
    "        dict: Analysis results\n",
    "    \"\"\"\n",
    "    show_details = options.get('show_details', True)\n",
    "    min_passing = options.get('min_passing_grade', 70)\n",
    "    \n",
    "    results = {\n",
    "        'total_classes': len(class_grades),\n",
    "        'class_stats': [],\n",
    "        'overall_average': 0,\n",
    "        'total_students': 0\n",
    "    }\n",
    "    \n",
    "    all_grades = []\n",
    "    \n",
    "    for i, grades in enumerate(class_grades, 1):\n",
    "        class_stats = calculate_grade_stats(grades)\n",
    "        if class_stats:\n",
    "            class_stats['class_number'] = i\n",
    "            class_stats['passing_rate_custom'] = (sum(1 for g in grades if g >= min_passing) / len(grades)) * 100\n",
    "            results['class_stats'].append(class_stats)\n",
    "            all_grades.extend(grades)\n",
    "            \n",
    "            if show_details:\n",
    "                print(f\"Class {i}: Avg {class_stats['average']:.1f}%, {class_stats['passing_rate_custom']:.1f}% passing\")\n",
    "    \n",
    "    if all_grades:\n",
    "        results['overall_average'] = sum(all_grades) / len(all_grades)\n",
    "        results['total_students'] = len(all_grades)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test functions\n",
    "print(\"Testing Function Mastery:\")\n",
    "\n",
    "# Test basic function\n",
    "sample_grades = [95, 87, 92, 78, 85, 90, 88]\n",
    "stats = calculate_grade_stats(sample_grades)\n",
    "print(f\"\\nGrade Statistics: Average {stats['average']:.1f}%, {stats['passing_rate']:.1f}% passing\")\n",
    "\n",
    "# Test function with defaults\n",
    "report = format_grade_report(\"Alice Johnson\", 88, attendance=95, extra_credit=5)\n",
    "print(f\"\\nSample Report:\\n{report}\")\n",
    "\n",
    "# Test function with *args/**kwargs\n",
    "class1_grades = [95, 87, 92, 78, 85]\n",
    "class2_grades = [88, 90, 76, 82, 94]\n",
    "class3_grades = [91, 89, 85, 88, 92]\n",
    "\n",
    "analysis = analyze_multiple_classes(class1_grades, class2_grades, class3_grades, \n",
    "                                  show_details=True, min_passing_grade=75)\n",
    "print(f\"\\nOverall Analysis: {analysis['total_students']} students across {analysis['total_classes']} classes\")\n",
    "print(f\"Overall Average: {analysis['overall_average']:.1f}%\")\n",
    "\n",
    "print(\"\\n✅ Functions mastery: Professional code organization achieved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "week3_review",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WEEK 3 REAL-WORLD SKILLS REVIEW\n",
    "print(\"\\n🌍 WEEK 3: REAL-WORLD SKILLS REVIEW\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 9. File I/O and Error Handling Mastery\n",
    "print(\"\\n📁 FILE I/O & ERROR HANDLING MASTERY:\")\n",
    "\n",
    "import csv\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def safe_data_processor(filename, output_format='json'):\n",
    "    \"\"\"\n",
    "    Safely process data file with comprehensive error handling\n",
    "    \n",
    "    Args:\n",
    "        filename (str): Input file path\n",
    "        output_format (str): Output format ('json' or 'csv')\n",
    "    \n",
    "    Returns:\n",
    "        dict: Processing results with success/error information\n",
    "    \"\"\"\n",
    "    results = {\n",
    "        'success': False,\n",
    "        'records_processed': 0,\n",
    "        'errors': [],\n",
    "        'output_file': None,\n",
    "        'processing_time': None\n",
    "    }\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    try:\n",
    "        # Attempt to read the file\n",
    "        processed_data = []\n",
    "        \n",
    "        with open(filename, 'r') as file:\n",
    "            # Try to determine file type\n",
    "            first_line = file.readline()\n",
    "            file.seek(0)  # Reset to beginning\n",
    "            \n",
    "            if ',' in first_line:  # Likely CSV\n",
    "                try:\n",
    "                    reader = csv.DictReader(file)\n",
    "                    for row_num, row in enumerate(reader, 1):\n",
    "                        try:\n",
    "                            # Process each row with validation\n",
    "                            if all(value.strip() for value in row.values()):\n",
    "                                processed_data.append(row)\n",
    "                                results['records_processed'] += 1\n",
    "                            else:\n",
    "                                results['errors'].append(f\"Row {row_num}: Empty fields found\")\n",
    "                        except Exception as e:\n",
    "                            results['errors'].append(f\"Row {row_num}: {str(e)}\")\n",
    "                            \n",
    "                except csv.Error as e:\n",
    "                    results['errors'].append(f\"CSV parsing error: {str(e)}\")\n",
    "                    return results\n",
    "                    \n",
    "            else:  # Try JSON\n",
    "                try:\n",
    "                    data = json.load(file)\n",
    "                    if isinstance(data, list):\n",
    "                        processed_data = data\n",
    "                        results['records_processed'] = len(data)\n",
    "                    else:\n",
    "                        processed_data = [data]\n",
    "                        results['records_processed'] = 1\n",
    "                except json.JSONDecodeError as e:\n",
    "                    results['errors'].append(f\"JSON parsing error: {str(e)}\")\n",
    "                    return results\n",
    "        \n",
    "        # Save processed data\n",
    "        if processed_data:\n",
    "            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "            \n",
    "            if output_format == 'json':\n",
    "                output_filename = f'processed_data_{timestamp}.json'\n",
    "                with open(output_filename, 'w') as outfile:\n",
    "                    json.dump({\n",
    "                        'processing_info': {\n",
    "                            'source_file': filename,\n",
    "                            'processed_at': datetime.now().isoformat(),\n",
    "                            'record_count': len(processed_data)\n",
    "                        },\n",
    "                        'data': processed_data\n",
    "                    }, outfile, indent=2)\n",
    "                    \n",
    "            else:  # CSV output\n",
    "                output_filename = f'processed_data_{timestamp}.csv'\n",
    "                if processed_data and isinstance(processed_data[0], dict):\n",
    "                    with open(output_filename, 'w', newline='') as outfile:\n",
    "                        fieldnames = list(processed_data[0].keys())\n",
    "                        writer = csv.DictWriter(outfile, fieldnames=fieldnames)\n",
    "                        writer.writeheader()\n",
    "                        writer.writerows(processed_data)\n",
    "            \n",
    "            results['output_file'] = output_filename\n",
    "            results['success'] = True\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        results['errors'].append(f\"File '{filename}' not found\")\n",
    "    except PermissionError:\n",
    "        results['errors'].append(f\"Permission denied accessing '{filename}'\")\n",
    "    except Exception as e:\n",
    "        results['errors'].append(f\"Unexpected error: {str(e)}\")\n",
    "    \n",
    "    finally:\n",
    "        end_time = datetime.now()\n",
    "        results['processing_time'] = (end_time - start_time).total_seconds()\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Create sample data for testing\n",
    "sample_data = [\n",
    "    {'name': 'Alice', 'score': 95, 'subject': 'Math'},\n",
    "    {'name': 'Bob', 'score': 87, 'subject': 'Math'},\n",
    "    {'name': 'Charlie', 'score': 92, 'subject': 'Math'}\n",
    "]\n",
    "\n",
    "# Create test CSV file\n",
    "with open('test_data.csv', 'w', newline='') as file:\n",
    "    fieldnames = ['name', 'score', 'subject']\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(sample_data)\n",
    "\n",
    "# Test file processing\n",
    "print(\"Testing File Processing:\")\n",
    "result = safe_data_processor('test_data.csv', 'json')\n",
    "\n",
    "if result['success']:\n",
    "    print(f\"✅ Successfully processed {result['records_processed']} records\")\n",
    "    print(f\"✅ Output saved to: {result['output_file']}\")\n",
    "    print(f\"✅ Processing time: {result['processing_time']:.3f} seconds\")\nelse:\n    print(f\"❌ Processing failed:\")\n    for error in result['errors']:\n        print(f\"   • {error}\")\n\n",
    "# Test error handling\n",
    "print(\"\\nTesting Error Handling:\")\n",
    "error_result = safe_data_processor('nonexistent_file.csv')\n",
    "print(f\"Error handling test: {len(error_result['errors'])} errors caught gracefully\")\n",
    "\n",
    "print(\"\\n✅ File I/O & Error Handling mastery: Production-ready code achieved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "week3_data_analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WEEK 3 DATA ANALYSIS MASTERY REVIEW\n",
    "print(\"\\n📊 WEEK 3: DATA ANALYSIS MASTERY REVIEW\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 10. Complete Data Analysis Pipeline\n",
    "print(\"\\n🔬 COMPLETE DATA ANALYSIS PIPELINE:\")\n",
    "\n",
    "class DataAnalysisPipeline:\n",
    "    \"\"\"\n",
    "    Complete data analysis pipeline demonstrating all skills\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, name=\"Data Analysis\"):\n",
    "        self.name = name\n",
    "        self.raw_data = []\n",
    "        self.clean_data = []\n",
    "        self.analysis_results = {}\n",
    "        self.insights = []\n",
    "        self.errors = []\n",
    "    \n",
    "    def load_data(self, data_source):\n",
    "        \"\"\"Load data from various sources\"\"\"\n",
    "        try:\n",
    "            if isinstance(data_source, str):  # File path\n",
    "                with open(data_source, 'r') as file:\n",
    "                    if data_source.endswith('.json'):\n",
    "                        self.raw_data = json.load(file)\n",
    "                    elif data_source.endswith('.csv'):\n",
    "                        reader = csv.DictReader(file)\n",
    "                        self.raw_data = list(reader)\n",
    "            elif isinstance(data_source, list):  # Direct data\n",
    "                self.raw_data = data_source\n",
    "            else:\n",
    "                raise ValueError(\"Unsupported data source type\")\n",
    "                \n",
    "            return len(self.raw_data)\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.errors.append(f\"Data loading error: {str(e)}\")\n",
    "            return 0\n",
    "    \n",
    "    def clean_data(self):\n",
    "        \"\"\"Clean and validate data\"\"\"\n",
    "        self.clean_data = []\n",
    "        \n",
    "        for i, record in enumerate(self.raw_data):\n",
    "            try:\n",
    "                # Skip empty or invalid records\n",
    "                if not record or not isinstance(record, dict):\n",
    "                    self.errors.append(f\"Record {i}: Invalid format\")\n",
    "                    continue\n",
    "                \n",
    "                # Clean string fields\n",
    "                clean_record = {}\n",
    "                for key, value in record.items():\n",
    "                    if isinstance(value, str):\n",
    "                        clean_record[key] = value.strip().title()\n",
    "                    elif isinstance(value, (int, float)):\n",
    "                        if value >= 0:  # Reject negative values for this example\n",
    "                            clean_record[key] = value\n",
    "                        else:\n",
    "                            self.errors.append(f\"Record {i}: Negative value for {key}\")\n",
    "                            continue\n",
    "                    else:\n",
    "                        clean_record[key] = value\n",
    "                \n",
    "                if clean_record:  # Only add if we have clean data\n",
    "                    self.clean_data.append(clean_record)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                self.errors.append(f\"Record {i}: Cleaning error - {str(e)}\")\n",
    "        \n",
    "        return len(self.clean_data)\n",
    "    \n",
    "    def analyze(self):\n",
    "        \"\"\"Perform comprehensive analysis\"\"\"\n",
    "        if not self.clean_data:\n",
    "            self.errors.append(\"No clean data available for analysis\")\n",
    "            return {}\n",
    "        \n",
    "        results = {\n",
    "            'record_count': len(self.clean_data),\n",
    "            'data_quality': {\n",
    "                'clean_records': len(self.clean_data),\n",
    "                'total_records': len(self.raw_data),\n",
    "                'error_count': len(self.errors),\n",
    "                'quality_score': (len(self.clean_data) / len(self.raw_data)) * 100 if self.raw_data else 0\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Analyze numeric fields\n",
    "        numeric_fields = []\n",
    "        for record in self.clean_data:\n",
    "            for key, value in record.items():\n",
    "                if isinstance(value, (int, float)) and key not in numeric_fields:\n",
    "                    numeric_fields.append(key)\n",
    "        \n",
    "        for field in numeric_fields:\n",
    "            values = [record[field] for record in self.clean_data if field in record]\n",
    "            if values:\n",
    "                results[f'{field}_stats'] = {\n",
    "                    'count': len(values),\n",
    "                    'sum': sum(values),\n",
    "                    'mean': sum(values) / len(values),\n",
    "                    'min': min(values),\n",
    "                    'max': max(values),\n",
    "                    'range': max(values) - min(values)\n",
    "                }\n",
    "        \n",
    "        # Analyze categorical fields\n",
    "        categorical_fields = []\n",
    "        for record in self.clean_data:\n",
    "            for key, value in record.items():\n",
    "                if isinstance(value, str) and key not in categorical_fields:\n",
    "                    categorical_fields.append(key)\n",
    "        \n",
    "        for field in categorical_fields:\n",
    "            values = [record[field] for record in self.clean_data if field in record]\n",
    "            if values:\n",
    "                from collections import Counter\n",
    "                counts = Counter(values)\n",
    "                results[f'{field}_distribution'] = {\n",
    "                    'unique_values': len(counts),\n",
    "                    'most_common': counts.most_common(3),\n",
    "                    'total_count': len(values)\n",
    "                }\n",
    "        \n",
    "        self.analysis_results = results\n",
    "        return results\n",
    "    \n",
    "    def generate_insights(self):\n",
    "        \"\"\"Generate business insights from analysis\"\"\"\n",
    "        insights = []\n",
    "        \n",
    "        if not self.analysis_results:\n",
    "            insights.append(\"No analysis results available for insight generation\")\n",
    "            return insights\n",
    "        \n",
    "        # Data quality insights\n",
    "        quality_score = self.analysis_results['data_quality']['quality_score']\n",
    "        if quality_score >= 95:\n",
    "            insights.append(f\"✅ Excellent data quality ({quality_score:.1f}%) - analysis is highly reliable\")\n",
    "        elif quality_score >= 85:\n",
    "            insights.append(f\"⚠️ Good data quality ({quality_score:.1f}%) - minor data issues detected\")\n",
    "        else:\n",
    "            insights.append(f\"❌ Poor data quality ({quality_score:.1f}%) - results should be interpreted carefully\")\n",
    "        \n",
    "        # Generate insights for numeric fields\n",
    "        for key, value in self.analysis_results.items():\n",
    "            if key.endswith('_stats'):\n",
    "                field_name = key.replace('_stats', '')\n",
    "                if value['range'] > value['mean'] * 2:\n",
    "                    insights.append(f\"📊 High variability in {field_name} (range: {value['range']:.1f}, mean: {value['mean']:.1f})\")\n",
    "                \n",
    "                if value['max'] > value['mean'] * 3:\n",
    "                    insights.append(f\"🔍 Potential outliers detected in {field_name} (max: {value['max']:.1f})\")\n",
    "        \n",
    "        # Generate insights for categorical fields\n",
    "        for key, value in self.analysis_results.items():\n",
    "            if key.endswith('_distribution'):\n",
    "                field_name = key.replace('_distribution', '')\n",
    "                if value['most_common']:\n",
    "                    top_category, count = value['most_common'][0]\n",
    "                    percentage = (count / value['total_count']) * 100\n",
    "                    if percentage > 50:\n",
    "                        insights.append(f\"📈 {field_name} heavily concentrated: '{top_category}' represents {percentage:.1f}% of data\")\n",
    "        \n",
    "        self.insights = insights\n",
    "        return insights\n",
    "    \n",
    "    def generate_report(self):\n",
    "        \"\"\"Generate comprehensive analysis report\"\"\"\n",
    "        report = f\"\"\"\n",
    "{'='*60}\n",
    "{self.name.upper()} - ANALYSIS REPORT\n",
    "{'='*60}\n",
    "\n",
    "📊 DATA OVERVIEW:\n",
    "   Records Loaded: {len(self.raw_data)}\n",
    "   Clean Records: {len(self.clean_data)}\n",
    "   Data Quality: {self.analysis_results.get('data_quality', {}).get('quality_score', 0):.1f}%\n",
    "   Errors Found: {len(self.errors)}\n",
    "\n",
    "🔍 KEY INSIGHTS:\"\"\"\n",
    "        \n",
    "        for insight in self.insights:\n",
    "            report += f\"\\n   • {insight}\"\n",
    "        \n",
    "        if self.errors:\n",
    "            report += \"\\n\\n⚠️ DATA QUALITY ISSUES:\"\n",
    "            for i, error in enumerate(self.errors[:5], 1):  # Show first 5 errors\n",
    "                report += f\"\\n   {i}. {error}\"\n",
    "            if len(self.errors) > 5:\n",
    "                report += f\"\\n   ... and {len(self.errors) - 5} more issues\"\n",
    "        \n",
    "        report += f\"\\n\\n📈 DETAILED STATISTICS:\"\n",
    "        for key, value in self.analysis_results.items():\n",
    "            if isinstance(value, dict) and 'mean' in value:\n",
    "                field_name = key.replace('_stats', '').title()\n",
    "                report += f\"\\n   {field_name}: avg={value['mean']:.1f}, range={value['min']:.1f}-{value['max']:.1f}\"\n",
    "        \n",
    "        report += \"\\n\" + \"=\"*60\n",
    "        return report.strip()\n",
    "\n",
    "# Test the complete pipeline\n",
    "print(\"Testing Complete Data Analysis Pipeline:\")\n",
    "\n",
    "# Create sample data with quality issues\n",
    "sample_student_data = [\n",
    "    {'name': 'alice johnson', 'score': 95, 'subject': 'math', 'attendance': 98},\n",
    "    {'name': 'BOB SMITH', 'score': 87, 'subject': 'MATH', 'attendance': 85},\n",
    "    {'name': '  charlie brown  ', 'score': 92, 'subject': 'math', 'attendance': 90},\n",
    "    {'name': '', 'score': 78, 'subject': 'math', 'attendance': 95},  # Missing name\n",
    "    {'name': 'diana prince', 'score': -5, 'subject': 'math', 'attendance': 88},  # Invalid score\n",
    "    {'name': 'eve wilson', 'score': 91, 'subject': 'math', 'attendance': 92},\n",
    "]\n",
    "\n",
    "# Run complete analysis\n",
    "pipeline = DataAnalysisPipeline(\"Student Performance Analysis\")\n",
    "records_loaded = pipeline.load_data(sample_student_data)\n",
    "clean_records = pipeline.clean_data()\n",
    "analysis = pipeline.analyze()\n",
    "insights = pipeline.generate_insights()\n",
    "report = pipeline.generate_report()\n",
    "\n",
    "print(f\"\\nPipeline Results:\")\n",
    "print(f\"Raw records: {records_loaded}, Clean records: {clean_records}\")\n",
    "print(f\"Quality score: {analysis['data_quality']['quality_score']:.1f}%\")\nprint(f\"Generated {len(insights)} insights\")\n\nprint(f\"\\n{report}\")\n\nprint(\"\\n✅ Complete Data Analysis Pipeline: MASTERED!\")\nprint(\"🎓 You can now build production-ready data analysis systems!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mastery_assessment",
   "metadata": {},
   "source": [
    "## 🏆 Mastery Assessment Challenge\n",
    "\n",
    "**Prove your mastery with this comprehensive challenge:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mastery_challenge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPREHENSIVE MASTERY CHALLENGE\n",
    "print(\"🏆 COMPREHENSIVE MASTERY CHALLENGE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"\"\"\n",
    "🎯 THE ULTIMATE PYTHON CHALLENGE:\n",
    "\n",
    "Build a COMPLETE DATA SCIENCE SYSTEM in 30 minutes that:\n",
    "\n",
    "✅ WEEK 1 SKILLS:\n",
    "   • Uses all major data types (strings, ints, floats, lists, dicts)\n",
    "   • Demonstrates string processing and formatting\n",
    "   • Shows mastery of list and dictionary operations\n",
    "\n",
    "✅ WEEK 2 SKILLS:\n",
    "   • Uses complex conditionals for business logic\n",
    "   • Implements loops for data processing\n",
    "   • Organizes code with well-designed functions\n",
    "\n",
    "✅ WEEK 3 SKILLS:\n",
    "   • Handles file I/O with error management\n",
    "   • Processes real data with cleaning/validation\n",
    "   • Generates actionable business insights\n",
    "\n",
    "🏗️ SYSTEM REQUIREMENTS:\n",
    "   1. Load data from CSV file\n",
    "   2. Clean and validate data quality\n",
    "   3. Perform statistical analysis\n",
    "   4. Generate business recommendations\n",
    "   5. Export results to JSON\n",
    "   6. Handle all errors gracefully\n",
    "   7. Include comprehensive documentation\n",
    "\n",
    "📊 SAMPLE SCENARIO: E-COMMERCE SALES ANALYSIS\n",
    "   • Analyze product sales performance\n",
    "   • Identify top customers and products\n",
    "   • Calculate revenue trends\n",
    "   • Generate inventory recommendations\n",
    "   • Predict future sales patterns\n",
    "\"\"\")\n",
    "\n",
    "# Create challenge dataset\n",
    "import csv\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def create_challenge_dataset():\n",
    "    \"\"\"Create the challenge dataset\"\"\"\n",
    "    print(\"\\n🔧 Creating challenge dataset...\")\n",
    "    \n",
    "    products = ['Laptop', 'Mouse', 'Keyboard', 'Monitor', 'Tablet', 'Phone', 'Headphones']\n",
    "    customers = ['Alice Smith', 'Bob Johnson', 'Charlie Brown', 'Diana Prince', 'Eve Wilson']\n",
    "    \n",
    "    challenge_data = []\n",
    "    base_date = datetime.now() - timedelta(days=30)\n",
    "    \n",
    "    for i in range(50):  # 50 sales records\n",
    "        date = (base_date + timedelta(days=random.randint(0, 30))).strftime('%Y-%m-%d')\n",
    "        customer = random.choice(customers)\n",
    "        product = random.choice(products)\n",
    "        quantity = random.randint(1, 5)\n",
    "        price = random.uniform(20, 1000)\n",
    "        \n",
    "        # Add some data quality issues\n",
    "        if i % 10 == 0:  # Every 10th record has issues\n",
    "            if i % 20 == 0:\n",
    "                customer = ''  # Missing customer\n",
    "            else:\n",
    "                quantity = -1  # Invalid quantity\n",
    "        \n",
    "        challenge_data.append({\n",
    "            'date': date,\n",
    "            'customer': customer,\n",
    "            'product': product,\n",
    "            'quantity': quantity,\n",
    "            'price': round(price, 2),\n",
    "            'total': round(quantity * price, 2)\n",
    "        })\n",
    "    \n",
    "    # Save challenge dataset\n",
    "    with open('challenge_sales_data.csv', 'w', newline='') as file:\n",
    "        fieldnames = ['date', 'customer', 'product', 'quantity', 'price', 'total']\n",
    "        writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(challenge_data)\n",
    "    \n",
    "    print(f\"✅ Challenge dataset created: {len(challenge_data)} records in 'challenge_sales_data.csv'\")\n",
    "    print(\"🎯 Dataset includes data quality issues for you to handle!\")\n",
    "\n",
    "# Create the challenge dataset\n",
    "create_challenge_dataset()\n",
    "\n",
    "print(\"\"\"\n",
    "⏰ YOUR 30-MINUTE CHALLENGE STARTS NOW!\n",
    "\n",
    "🎯 SUCCESS CRITERIA:\n",
    "   • System processes all data without crashing\n",
    "   • Generates meaningful business insights\n",
    "   • Exports results to JSON format\n",
    "   • Code is well-organized with functions\n",
    "   • Includes proper error handling\n",
    "   • Documentation explains your approach\n",
    "\n",
    "💡 HINTS:\n",
    "   • Start with data loading and cleaning\n",
    "   • Build incrementally - test each function\n",
    "   • Focus on the most important insights first\n",
    "   • Remember: working code beats perfect code\n",
    "\n",
    "🚀 GO! Show us your Python mastery!\n",
    "\"\"\")\n",
    "\n",
    "# Challenge implementation space\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"YOUR CHALLENGE IMPLEMENTATION GOES BELOW:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# TODO: Implement your complete data science system here!\n",
    "# Use all the skills you've learned across the 3 weeks\n",
    "\n",
    "class MasteryChallengeSystem:\n",
    "    \"\"\"Your mastery challenge implementation\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # TODO: Initialize your system\n",
    "        pass\n",
    "    \n",
    "    def load_and_clean_data(self, filename):\n",
    "        \"\"\"TODO: Load and clean the challenge dataset\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def analyze_sales_performance(self):\n",
    "        \"\"\"TODO: Analyze sales performance\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def generate_insights(self):\n",
    "        \"\"\"TODO: Generate business insights\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def export_results(self, filename):\n",
    "        \"\"\"TODO: Export results to JSON\"\"\"\n",
    "        pass\n",
    "\n",
    "# TODO: Run your system\n",
    "# system = MasteryChallengeSystem()\n",
    "# system.load_and_clean_data('challenge_sales_data.csv')\n",
    "# system.analyze_sales_performance()\n",
    "# insights = system.generate_insights()\n",
    "# system.export_results('challenge_results.json')\n",
    "# print(insights)\n",
    "\n",
    "print(\"\\n⏰ Timer starts when you begin implementing!\")\nprint(\"🏆 Show us what you've learned!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final_project_launch",
   "metadata": {},
   "source": [
    "## 🚀 Final Project Launch\n",
    "\n",
    "**Your capstone project - the culmination of your Python journey!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final_project_intro",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINAL PROJECT INTRODUCTION\n",
    "print(\"🚀 FINAL PROJECT LAUNCH\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"\"\"\n",
    "🎓 CONGRATULATIONS! You're ready for your CAPSTONE PROJECT!\n",
    "\n",
    "This is your chance to:\n",
    "   ✨ Demonstrate mastery of all Python fundamentals\n",
    "   ✨ Solve a real business problem with data\n",
    "   ✨ Build a portfolio-worthy project\n",
    "   ✨ Show your growth from beginner to data scientist\n",
    "\n",
    "🎯 PROJECT OVERVIEW:\n",
    "   • Duration: 1 week (work at your own pace)\n",
    "   • Individual project with instructor support\n",
    "   • Choice of 3 compelling business scenarios\n",
    "   • Real datasets with genuine challenges\n",
    "   • Professional presentation of findings\n",
    "\n",
    "📊 WHAT YOU'LL BUILD:\n",
    "   1. Complete data analysis system from scratch\n",
    "   2. Professional data processing pipeline\n",
    "   3. Business intelligence dashboard data\n",
    "   4. Executive summary with recommendations\n",
    "   5. Technical documentation for your code\n",
    "   6. Presentation-ready insights and visuals\n",
    "\n",
    "🏆 PROJECT THEMES TO CHOOSE FROM:\n",
    "\"\"\")\n",
    "\n",
    "project_themes = {\n",
    "    \"Healthcare Analytics\": {\n",
    "        \"description\": \"Analyze patient outcomes and hospital efficiency\",\n",
    "        \"business_value\": \"Improve patient care and reduce costs\",\n",
    "        \"datasets\": \"Patient records, treatment outcomes, resource utilization\",\n",
    "        \"skills_focus\": \"Data cleaning, statistical analysis, outcome prediction\",\n",
    "        \"deliverables\": \"Risk assessment model, efficiency recommendations\"\n",
    "    },\n",
    "    \n",
    "    \"Financial Services\": {\n",
    "        \"description\": \"Credit risk analysis and fraud detection system\",\n",
    "        \"business_value\": \"Reduce financial losses and improve decision-making\",\n",
    "        \"datasets\": \"Transaction history, credit scores, demographic data\",\n",
    "        \"skills_focus\": \"Pattern recognition, anomaly detection, risk modeling\",\n",
    "        \"deliverables\": \"Fraud detection rules, credit scoring model\"\n",
    "    },\n",
    "    \n",
    "    \"Retail Intelligence\": {\n",
    "        \"description\": \"Customer behavior and inventory optimization\",\n",
    "        \"business_value\": \"Increase sales and improve customer satisfaction\",\n",
    "        \"datasets\": \"Sales history, customer demographics, inventory data\",\n",
    "        \"skills_focus\": \"Customer segmentation, demand forecasting, optimization\",\n",
    "        \"deliverables\": \"Customer insights, inventory recommendations\"\n",
    "    }\n",
    "}\n",
    "\n",
    "for theme, details in project_themes.items():\n",
    "    print(f\"\\n🔹 {theme.upper()}:\")\n",
    "    print(f\"   📋 Description: {details['description']}\")\n",
    "    print(f\"   💼 Business Value: {details['business_value']}\")\n",
    "    print(f\"   📊 Data Sources: {details['datasets']}\")\n",
    "    print(f\"   🎯 Skills Focus: {details['skills_focus']}\")\n",
    "    print(f\"   📈 Key Deliverables: {details['deliverables']}\")\n",
    "\n",
    "print(\"\"\"\n",
    "\n",
    "📋 PROJECT REQUIREMENTS:\n",
    "\n",
    "🔧 TECHNICAL REQUIREMENTS:\n",
    "   • Data loading with comprehensive error handling\n",
    "   • Data cleaning and quality validation\n",
    "   • Statistical analysis with Python fundamentals\n",
    "   • Business intelligence generation\n",
    "   • Results export to multiple formats (JSON, CSV)\n",
    "   • Professional code documentation\n",
    "   • Comprehensive testing and validation\n",
    "\n",
    "📊 ANALYSIS REQUIREMENTS:\n",
    "   • Exploratory data analysis with insights\n",
    "   • Key performance indicators (KPIs)\n",
    "   • Trend analysis and pattern identification\n",
    "   • Business recommendations with data support\n",
    "   • Risk assessment and opportunity identification\n",
    "   • Data visualization preparation (dashboard-ready)\n",
    "\n",
    "📝 DELIVERABLES:\n",
    "   1. Complete Python analysis system (Jupyter notebook)\n",
    "   2. Executive summary report (PDF/Markdown)\n",
    "   3. Technical documentation (README with setup)\n",
    "   4. Data quality assessment report\n",
    "   5. Business recommendations presentation\n",
    "   6. Code portfolio ready for job interviews\n",
    "\n",
    "⏰ TIMELINE:\n",
    "   • Week 4: Project planning and data exploration\n",
    "   • Week 5: Core development and analysis\n",
    "   • Week 6: Testing, documentation, and presentation prep\n",
    "   • Week 7: Final presentations and peer review\n",
    "\n",
    "🎯 SUCCESS CRITERIA:\n",
    "   • System processes real data without errors\n",
    "   • Generates actionable business insights\n",
    "   • Code demonstrates mastery of Python fundamentals\n",
    "   • Professional presentation suitable for stakeholders\n",
    "   • Portfolio-ready project for job applications\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n🎉 YOUR FINAL PROJECT AWAITS!\")\nprint(\"This is your chance to shine and show the world what you've learned!\")\nprint(\"\\n📋 Next steps: Choose your theme and begin planning!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "career_guidance",
   "metadata": {},
   "source": [
    "## 💼 Career Guidance & Next Steps\n",
    "\n",
    "**Your path from here to data science success:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "career_roadmap",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAREER ROADMAP AND GUIDANCE\n",
    "print(\"💼 YOUR DATA SCIENCE CAREER ROADMAP\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "career_path = {\n",
    "    \"IMMEDIATE (Next 1-2 months)\": {\n",
    "        \"technical_skills\": [\n",
    "            \"Master pandas for data manipulation\",\n",
    "            \"Learn NumPy for numerical computing\",\n",
    "            \"Introduction to data visualization (Matplotlib, Seaborn)\",\n",
    "            \"Basic SQL for database interaction\",\n",
    "            \"Git version control for code management\"\n",
    "        ],\n",
    "        \"projects\": [\n",
    "            \"Complete 2-3 guided pandas tutorials\",\n",
    "            \"Recreate your Python projects using pandas\",\n",
    "            \"Build a simple web scraping project\",\n",
    "            \"Create interactive visualizations\"\n",
    "        ],\n",
    "        \"portfolio\": [\n",
    "            \"Create GitHub account and upload projects\",\n",
    "            \"Write professional README files\",\n",
    "            \"Document your learning journey\",\n",
    "            \"Start a data science blog or LinkedIn articles\"\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    \"SHORT-TERM (3-6 months)\": {\n",
    "        \"technical_skills\": [\n",
    "            \"Advanced pandas and data wrangling\",\n",
    "            \"Machine learning basics (scikit-learn)\",\n",
    "            \"Statistical analysis and hypothesis testing\",\n",
    "            \"Web development basics (Flask/FastAPI)\",\n",
    "            \"Cloud platforms introduction (AWS/GCP)\"\n",
    "        ],\n",
    "        \"projects\": [\n",
    "            \"Build 3-5 end-to-end ML projects\",\n",
    "            \"Create a web-based data dashboard\",\n",
    "            \"Participate in Kaggle competitions\",\n",
    "            \"Contribute to open-source projects\"\n",
    "        ],\n",
    "        \"career_prep\": [\n",
    "            \"Network with data professionals\",\n",
    "            \"Attend data science meetups/conferences\",\n",
    "            \"Practice technical interviews\",\n",
    "            \"Apply for junior data analyst positions\"\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    \"MEDIUM-TERM (6-12 months)\": {\n",
    "        \"technical_skills\": [\n",
    "            \"Deep learning frameworks (TensorFlow/PyTorch)\",\n",
    "            \"Advanced SQL and database design\",\n",
    "            \"Big data tools (Spark, Hadoop)\",\n",
    "            \"MLOps and model deployment\",\n",
    "            \"Specialized domains (NLP, Computer Vision)\"\n",
    "        ],\n",
    "        \"career_goals\": [\n",
    "            \"Secure first data science role\",\n",
    "            \"Build reputation in data community\",\n",
    "            \"Mentor other aspiring data scientists\",\n",
    "            \"Speak at conferences or meetups\"\n",
    "        ],\n",
    "        \"specialization\": [\n",
    "            \"Choose specialization (ML Engineer, Data Analyst, etc.)\",\n",
    "            \"Develop domain expertise (healthcare, finance, etc.)\",\n",
    "            \"Build advanced portfolio projects\",\n",
    "            \"Consider advanced degrees or certifications\"\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "for timeframe, goals in career_path.items():\n",
    "    print(f\"\\n🎯 {timeframe}:\")\n",
    "    for category, items in goals.items():\n",
    "        print(f\"\\n   {category.replace('_', ' ').title()}:\")\n",
    "        for item in items:\n",
    "            print(f\"   • {item}\")\n",
    "\n",
    "print(\"\"\"\n",
    "\n",
    "💰 SALARY EXPECTATIONS:\n",
    "   🥉 Junior Data Analyst: $45,000 - $65,000\n",
    "   🥈 Data Scientist I: $70,000 - $95,000\n",
    "   🥇 Senior Data Scientist: $100,000 - $150,000\n",
    "   🏆 Principal/Staff: $150,000 - $250,000+\n",
    "\n",
    "🎯 JOB TITLES TO TARGET:\n",
    "   📊 Entry Level: Data Analyst, Junior Data Scientist, Business Analyst\n",
    "   📈 Mid Level: Data Scientist, ML Engineer, Analytics Manager\n",
    "   🚀 Senior Level: Senior Data Scientist, Head of Analytics, Chief Data Officer\n",
    "\n",
    "🏢 COMPANIES HIRING:\n",
    "   💼 Tech: Google, Microsoft, Amazon, Meta, Netflix\n",
    "   🏦 Finance: JPMorgan, Goldman Sachs, Bank of America\n",
    "   🏥 Healthcare: Johnson & Johnson, Pfizer, UnitedHealth\n",
    "   🛒 Retail: Walmart, Target, Amazon, Shopify\n",
    "   🚗 Automotive: Tesla, Ford, GM, Uber, Lyft\n",
    "\n",
    "📚 LEARNING RESOURCES:\n",
    "\n",
    "   🆓 FREE RESOURCES:\n",
    "   • Kaggle Learn (free courses)\n",
    "   • YouTube: 3Blue1Brown, StatQuest, Corey Schafer\n",
    "   • GitHub: Awesome Data Science lists\n",
    "   • Papers With Code (latest ML research)\n",
    "   • Google Colab (free GPU access)\n",
    "\n",
    "   💳 PAID RESOURCES:\n",
    "   • DataCamp, Coursera, edX specializations\n",
    "   • Udacity Data Science Nanodegree\n",
    "   • Fast.ai courses\n",
    "   • O'Reilly Learning Platform\n",
    "   • Pluralsight technology tracks\n",
    "\n",
    "🤝 NETWORKING & COMMUNITY:\n",
    "   • Join local data science meetups\n",
    "   • Participate in Kaggle competitions\n",
    "   • Contribute to open-source projects\n",
    "   • Follow data science influencers on LinkedIn/Twitter\n",
    "   • Attend conferences (PyData, Strata, KDD)\n",
    "\n",
    "🎯 KEY SUCCESS FACTORS:\n",
    "   ✨ Never stop learning - technology evolves rapidly\n",
    "   ✨ Build projects that solve real problems\n",
    "   ✨ Communicate insights clearly to non-technical audiences\n",
    "   ✨ Stay curious and ask great questions\n",
    "   ✨ Network authentically and help others\n",
    "   ✨ Embrace failure as learning opportunities\n",
    "\n",
    "🚀 REMEMBER: You already have the foundation!\n",
    "   Everything else builds on the Python fundamentals you've mastered.\n",
    "   You're not starting from zero - you're accelerating from a strong base!\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n💪 You have everything you need to succeed!\")\nprint(\"🌟 Your data science career starts now!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final_celebration",
   "metadata": {},
   "source": [
    "## 🎉 Final Celebration & Reflection\n",
    "\n",
    "**Take a moment to appreciate your incredible journey:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "celebration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINAL CELEBRATION AND REFLECTION\n",
    "print(\"🎉 FINAL CELEBRATION & COURSE REFLECTION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\"\"\n",
    "🏆 CONGRATULATIONS! You've completed an EXTRAORDINARY journey!\n",
    "\n",
    "📈 YOUR TRANSFORMATION:\n",
    "   • 3 weeks ago: Complete Python beginner\n",
    "   • Today: Confident data scientist ready for real-world challenges\n",
    "   • Skills gained: 50+ Python concepts and techniques\n",
    "   • Projects built: 6+ complete data analysis systems\n",
    "   • Lines of code written: 1000+ lines of professional Python\n",
    "\n",
    "🎯 WHAT MAKES YOU SPECIAL:\n",
    "   ✨ You didn't just learn syntax - you developed data intuition\n",
    "   ✨ You can solve real business problems with code\n",
    "   ✨ You understand what happens 'under the hood' in data science\n",
    "   ✨ You can communicate technical insights to business audiences\n",
    "   ✨ You have the foundation for any advanced data science topic\n",
    "\n",
    "🔧 TECHNICAL SKILLS MASTERED:\n",
    "   • Variables, data types, and type conversion\n",
    "   • String processing and text analysis\n",
    "   • Lists, dictionaries, and complex data structures\n",
    "   • Conditional logic and decision-making systems\n",
    "   • Loops for efficient data processing\n",
    "   • Functions for code organization and reusability\n",
    "   • File I/O and data format handling (CSV, JSON)\n",
    "   • Error handling and robust system design\n",
    "   • Statistical analysis and insight generation\n",
    "   • Complete data analysis pipeline development\n",
    "\n",
    "💼 PROFESSIONAL SKILLS GAINED:\n",
    "   • Problem decomposition and systematic thinking\n",
    "   • Data quality assessment and cleaning\n",
    "   • Business communication and stakeholder reporting\n",
    "   • Project planning and execution\n",
    "   • Testing, debugging, and quality assurance\n",
    "   • Technical documentation and code comments\n",
    "   • Presentation skills for technical audiences\n",
    "\n",
    "🚀 WHAT YOU'RE READY FOR:\n",
    "   • Junior Data Analyst positions\n",
    "   • Advanced Python libraries (pandas, NumPy, scikit-learn)\n",
    "   • Machine learning and statistical modeling\n",
    "   • Database integration and SQL\n",
    "   • Web development and API integration\n",
    "   • Cloud computing and big data platforms\n",
    "   • Specialized domains (NLP, Computer Vision, etc.)\n",
    "\n",
    "📊 BY THE NUMBERS:\n",
    "   🕒 Hours invested: 30+ hours of dedicated learning\n",
    "   📝 Concepts mastered: 50+ Python fundamentals\n",
    "   🏗️ Projects completed: 6+ end-to-end systems\n",
    "   💾 Code written: 1000+ lines of professional Python\n",
    "   🎯 Skills assessment: From 0% to 85%+ Python proficiency\n",
    "   💡 'Aha!' moments: Countless discoveries and breakthroughs\n",
    "   🌟 Confidence gained: Immeasurable!\n",
    "\n",
    "🎓 WHAT SETS YOU APART:\n",
    "   Unlike typical programming courses that focus on syntax,\n",
    "   you've learned to THINK like a data scientist:\n",
    "   \n",
    "   • You approach problems systematically\n",
    "   • You question data quality and validate assumptions\n",
    "   • You focus on business value, not just technical complexity\n",
    "   • You communicate insights that drive decisions\n",
    "   • You build robust systems that handle real-world messiness\n",
    "\n",
    "💝 PERSONAL MESSAGE:\n",
    "   The transformation you've achieved in just 3 weeks is remarkable.\n",
    "   You've proven that with dedication, curiosity, and the right\n",
    "   guidance, anyone can become a data scientist.\n",
    "   \n",
    "   You didn't just learn Python - you developed a new way of\n",
    "   thinking about problems, data, and solutions. This mindset\n",
    "   will serve you throughout your entire career.\n",
    "   \n",
    "   Remember: every expert was once a beginner. You've taken the\n",
    "   hardest step - getting started. Now you have the foundation\n",
    "   to build whatever you can imagine.\n",
    "\n",
    "🌟 YOUR FUTURE IS BRIGHT:\n",
    "   • The data science field is growing rapidly\n",
    "   • Companies desperately need skilled data professionals\n",
    "   • You have both technical skills AND business acumen\n",
    "   • Your foundation is solid and will serve you for years\n",
    "   • The community is supportive and collaborative\n",
    "\n",
    "🎯 FINAL WORDS OF WISDOM:\n",
    "   1. Keep coding - use it or lose it!\n",
    "   2. Build projects that excite you\n",
    "   3. Don't be afraid to tackle challenging problems\n",
    "   4. Help others who are starting their journey\n",
    "   5. Stay curious and never stop learning\n",
    "   6. Remember: you're a data scientist now!\n",
    "\n",
    "🎊 THANK YOU for being amazing students!\n",
    "🚀 Go forth and change the world with data!\n",
    "💫 The future of data science is in great hands with you!\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "# Course completion certificate\nfrom datetime import datetime\n\ncertificate = f\"\"\"\n",
    "{'*'*70}\n",
    "         🎓 CERTIFICATE OF COMPLETION 🎓\n",
    "{'*'*70}\n",
    "\n",
    "                    This certifies that\n",
    "\n",
    "                    [YOUR NAME HERE]\n",
    "\n",
    "              has successfully completed the\n",
    "\n",
    "          PYTHON FUNDAMENTALS FOR DATA SCIENCE\n",
    "                  Intensive Bootcamp\n",
    "\n",
    "              Demonstrating mastery of:\n",
    "         • Python Programming Fundamentals\n",
    "         • Data Analysis and Processing\n",
    "         • Business Intelligence Generation\n",
    "         • Professional Development Practices\n",
    "\n",
    "         Completion Date: {datetime.now().strftime('%B %d, %Y')}\n",
    "         Course Duration: 3 Intensive Weeks\n",
    "         Projects Completed: 6+ Data Science Systems\n",
    "\n",
    "     🌟 You are now ready to tackle real-world data\n",
    "         science challenges with confidence! 🌟\n",
    "\n",
    "{'*'*70}\n",
    "\"\"\"\n",
    "\nprint(certificate)\n\nprint(\"\\n🎉 CONGRATULATIONS, DATA SCIENTIST!\")\nprint(\"🚀 Your journey is just beginning!\")\nprint(\"💫 Go change the world with your new superpowers!\")\n\n# Final stats display\nprint(f\"\\n📊 FINAL COURSE STATISTICS:\")\nprint(f\"   Course completed: {datetime.now().strftime('%B %d, %Y')}\")\nprint(f\"   Total lessons: 12 comprehensive sessions\")\nprint(f\"   Skills mastered: 50+ Python concepts\")\nprint(f\"   Projects built: 6+ complete systems\")\nprint(f\"   Ready for: Advanced data science topics\")\nprint(f\"   Career potential: $45,000+ starting salary\")\nprint(f\"   Pride level: MAXIMUM! 🏆\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "course_conclusion",
   "metadata": {},
   "source": [
    "## 🎓 Course Conclusion\n",
    "\n",
    "**You did it! From Python beginner to data scientist in just 3 weeks!**\n",
    "\n",
    "### 🏆 What You've Accomplished\n",
    "This wasn't just a Python course - it was a complete transformation. You've developed:\n",
    "\n",
    "- **💻 Technical Mastery**: All essential Python skills for data science\n",
    "- **🧠 Analytical Thinking**: Problem-solving approaches that scale\n",
    "- **📊 Data Intuition**: Understanding of how to extract insights\n",
    "- **💼 Professional Skills**: Code organization, documentation, and communication\n",
    "- **🚀 Career Readiness**: Portfolio projects and real-world experience\n",
    "\n",
    "### 🌟 What Makes You Special\n",
    "Unlike many who learn Python syntax, you learned to **think** like a data scientist:\n",
    "- You question data quality and validate assumptions\n",
    "- You focus on business value, not just technical complexity\n",
    "- You build systems that handle real-world messiness\n",
    "- You communicate insights that drive decisions\n",
    "\n",
    "### 🎯 Your Next Steps\n",
    "1. **Complete your final project** - make it portfolio-worthy!\n",
    "2. **Master pandas and visualization** - build on your solid foundation\n",
    "3. **Network and apply** - you're ready for junior data roles\n",
    "4. **Keep building** - practice makes permanent\n",
    "5. **Help others** - teach what you've learned\n",
    "\n",
    "### 💝 A Personal Thank You\n",
    "Teaching you has been an incredible privilege. Watching complete beginners transform into confident data scientists in just 3 weeks never stops being amazing. \n",
    "\n",
    "You've proven that with dedication, good instruction, and hands-on practice, anyone can master these skills. You should be incredibly proud of what you've accomplished.\n",
    "\n",
    "### 🚀 Go Change the World\n",
    "Data science is one of the most impactful fields in technology. You now have the skills to:\n",
    "- Help healthcare systems save lives through better analysis\n",
    "- Enable businesses to make smarter decisions\n",
    "- Fight climate change with environmental data\n",
    "- Advance scientific research across all domains\n",
    "- Build the AI systems of tomorrow\n",
    "\n",
    "**The world needs more thoughtful, skilled data scientists like you.**\n",
    "\n",
    "---\n",
    "\n",
    "### 🎊 Final Message\n",
    "\n",
    "*\"Three weeks ago, you couldn't write a simple Python program. Today, you can build complete data analysis systems that solve real business problems. This transformation is proof of your potential - there's no limit to what you can achieve when you set your mind to it.\"*\n",
    "\n",
    "*\"You're not just Python programmers now - you're data scientists, problem solvers, and future leaders in one of the world's most important fields.\"*\n",
    "\n",
    "*\"Go forth with confidence, curiosity, and compassion. The future of data science is in excellent hands with you!\"*\n",
    "\n",
    "**🎓 Congratulations, Data Scientists! 🎓**\n",
    "\n",
    "**🚀 Your adventure is just beginning! 🚀**\n",
    "\n",
    "---\n",
    "\n",
    "## 📧 Stay Connected\n",
    "- **Questions**: Always feel free to reach out\n",
    "- **Updates**: Share your career progress\n",
    "- **Projects**: Show off what you build next\n",
    "- **Community**: Help the next cohort of students\n",
    "\n",
    "**Once a student, always part of the family!** 💙"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}