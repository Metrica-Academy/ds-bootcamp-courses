{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🚀 Data Science Bootcamp: Hands-On Exercises\n",
    "\n",
    "---\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"figs/a_lab_flask_with_data_points.png\" width=\"300\"/>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 Welcome to Your Data Science Lab!\n",
    "\n",
    "Congratulations on completing the introduction session! Now it's time to **apply what you've learned** and build your data science portfolio with real-world datasets.\n",
    "\n",
    "### 📚 What You'll Accomplish:\n",
    "\n",
    "In this hands-on exercise notebook, you'll work with **5 exciting new datasets** to:\n",
    "\n",
    "✨ **Analyze Netflix viewing habits** and discover binge-watching patterns  \n",
    "🛍️ **Optimize retail sales strategies** using transaction data  \n",
    "🎵 **Explore Spotify music trends** and build recommendation insights  \n",
    "🌤️ **Investigate weather patterns** and climate trends  \n",
    "📱 **Decode social media engagement** and viral content secrets  \n",
    "\n",
    "### 🎪 How This Works:\n",
    "\n",
    "Each exercise includes:\n",
    "- **📋 Clear Instructions** - Step-by-step guidance\n",
    "- **💡 Hints & Tips** - Helpful suggestions when you need them\n",
    "- **✍️ TODO Sections** - Your space to write code\n",
    "- **🎯 Challenges** - Optional advanced tasks\n",
    "- **✅ Self-Check Questions** - Verify your understanding\n",
    "\n",
    "### 🏆 Your Goal:\n",
    "\n",
    "Complete all 5 exercises to build a **professional data science portfolio** showcasing:\n",
    "- Data exploration and cleaning\n",
    "- Statistical analysis\n",
    "- Visualization mastery\n",
    "- Business insights generation\n",
    "- Storytelling with data\n",
    "\n",
    "---\n",
    "\n",
    "<div style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 20px; border-radius: 10px; margin: 20px 0; text-align: center;\">\n",
    "    <h3>💪 Ready to Level Up Your Skills?</h3>\n",
    "    <p style=\"font-size: 18px;\">Let's dive into real data and discover amazing insights!</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ⚙️ Setup & Configuration\n",
    "\n",
    "First, let's set up your data science environment with all the tools you'll need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "\n",
    "# Import our custom utilities\n",
    "from data_science_utils import (\n",
    "    MyDataScienceKit, PlottingUtils, DataAnalysisUtils,\n",
    "    create_environment_checker\n",
    ")\n",
    "from interactive_components import InteractiveQuiz, DataExplorer\n",
    "\n",
    "# Configuration\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(42)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# Initialize your toolkit\n",
    "my_kit = MyDataScienceKit(\"Data Science Explorer\")\n",
    "\n",
    "print(\"🎉 Environment Setup Complete!\")\n",
    "print(\"=\"*50)\n",
    "print(create_environment_checker())\n",
    "print(\"=\"*50)\n",
    "print(\"\\n🚀 You're ready to start your exercises!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 📊 Exercise 1: Netflix Binge-Watching Analytics 🎬\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"figs/visualization-example.png\" width=\"400\"/>\n",
    "</div>\n",
    "\n",
    "### 🎯 Objective\n",
    "Analyze Netflix viewing patterns to understand user behavior, content preferences, and binge-watching habits.\n",
    "\n",
    "### 📋 Your Tasks:\n",
    "1. Load and explore the Netflix viewing data\n",
    "2. Identify the most popular shows and genres\n",
    "3. Analyze viewing patterns by time of day\n",
    "4. Investigate device preferences\n",
    "5. Calculate completion rates and identify binge-worthy content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Netflix dataset\n",
    "netflix_df = pd.read_csv('datasets/netflix_viewing_data.csv')\n",
    "\n",
    "print(\"🎬 Netflix Viewing Data Loaded!\")\n",
    "print(f\"📊 Dataset Shape: {netflix_df.shape}\")\n",
    "print(f\"👥 Unique Users: {netflix_df['user_id'].nunique()}\")\n",
    "print(f\"📺 Unique Shows: {netflix_df['show'].nunique()}\")\n",
    "print(\"\\n📋 Dataset Overview:\")\n",
    "display(netflix_df.head())\n",
    "print(\"\\n📊 Data Types:\")\n",
    "print(netflix_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📺 Task 1.1: Most Popular Shows\n",
    "\n",
    "**TODO:** Find the top 10 most-watched shows and visualize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate the most popular shows\n",
    "# Hint: Use value_counts() or groupby() to count show occurrences\n",
    "\n",
    "# Your code here:\n",
    "popular_shows = netflix_df['show'].value_counts().head(10)\n",
    "\n",
    "# Visualization\n",
    "fig, ax = PlottingUtils.create_bar_chart(\n",
    "    dict(popular_shows),\n",
    "    title=\"🏆 Top 10 Most-Watched Netflix Shows\",\n",
    "    xlabel=\"Shows\",\n",
    "    ylabel=\"Number of Views\",\n",
    "    figsize=(12, 6)\n",
    ")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n📊 Top 5 Shows:\")\n",
    "for i, (show, count) in enumerate(popular_shows.head().items(), 1):\n",
    "    print(f\"{i}. {show}: {count} views\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🎭 Task 1.2: Genre Analysis\n",
    "\n",
    "**TODO:** Analyze genre preferences and viewing patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Analyze genres\n",
    "# Your code here:\n",
    "\n",
    "# Genre distribution\n",
    "genre_counts = netflix_df['genre'].value_counts()\n",
    "\n",
    "# Average watch time by genre\n",
    "genre_watch_time = netflix_df.groupby('genre').agg({\n",
    "    'watch_time_minutes': ['mean', 'sum', 'count'],\n",
    "    'rating': 'mean',\n",
    "    'completed': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "genre_watch_time.columns = ['avg_watch_time', 'total_watch_time', 'view_count', 'avg_rating', 'completion_rate']\n",
    "genre_watch_time = genre_watch_time.sort_values('total_watch_time', ascending=False)\n",
    "\n",
    "print(\"🎭 Genre Analysis:\")\n",
    "display(genre_watch_time)\n",
    "\n",
    "# Create a pie chart for genre distribution\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Pie chart\n",
    "colors = PlottingUtils.COLORS['palette'][:len(genre_counts)]\n",
    "ax1.pie(genre_counts.values, labels=genre_counts.index, autopct='%1.1f%%', colors=colors)\n",
    "ax1.set_title('📊 Genre Distribution', fontweight='bold')\n",
    "\n",
    "# Bar chart for completion rates\n",
    "ax2.bar(genre_watch_time.index, genre_watch_time['completion_rate'], color=colors)\n",
    "ax2.set_title('✅ Completion Rate by Genre', fontweight='bold')\n",
    "ax2.set_xlabel('Genre')\n",
    "ax2.set_ylabel('Completion Rate')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🕐 Task 1.3: Time of Day Analysis\n",
    "\n",
    "**TODO:** When do people watch Netflix the most?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Analyze viewing patterns by time of day\n",
    "# Your code here:\n",
    "\n",
    "time_analysis = netflix_df.groupby('time_of_day').agg({\n",
    "    'user_id': 'count',\n",
    "    'watch_time_minutes': 'mean',\n",
    "    'completed': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "time_analysis.columns = ['view_count', 'avg_watch_time', 'completion_rate']\n",
    "time_analysis = time_analysis.sort_values('view_count', ascending=False)\n",
    "\n",
    "print(\"🕐 Viewing Patterns by Time of Day:\")\n",
    "display(time_analysis)\n",
    "\n",
    "# Visualization\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "x = range(len(time_analysis))\n",
    "bars = ax.bar(x, time_analysis['view_count'], color=PlottingUtils.COLORS['palette'][:len(time_analysis)])\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(time_analysis.index)\n",
    "ax.set_title('📺 Netflix Viewing by Time of Day', fontweight='bold', fontsize=14)\n",
    "ax.set_xlabel('Time of Day')\n",
    "ax.set_ylabel('Number of Views')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, value in zip(bars, time_analysis['view_count']):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 20,\n",
    "            f'{int(value)}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Insight\n",
    "peak_time = time_analysis.index[0]\n",
    "print(f\"\\n🎯 Key Insight: Peak viewing time is during {peak_time} with {time_analysis.iloc[0]['view_count']:.0f} views!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📱 Task 1.4: Device Analysis\n",
    "\n",
    "**TODO:** Which devices do users prefer for watching content?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Analyze device preferences\n",
    "# Your code here:\n",
    "\n",
    "device_analysis = netflix_df.groupby('device').agg({\n",
    "    'user_id': 'count',\n",
    "    'watch_time_minutes': 'mean',\n",
    "    'completed': lambda x: (x == True).mean(),\n",
    "    'rating': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "device_analysis.columns = ['usage_count', 'avg_watch_time', 'completion_rate', 'avg_rating']\n",
    "\n",
    "print(\"📱 Device Usage Analysis:\")\n",
    "display(device_analysis)\n",
    "\n",
    "# Create visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Device usage count\n",
    "axes[0, 0].bar(device_analysis.index, device_analysis['usage_count'], \n",
    "               color=PlottingUtils.COLORS['palette'][:len(device_analysis)])\n",
    "axes[0, 0].set_title('📱 Device Usage Count')\n",
    "axes[0, 0].set_ylabel('Number of Views')\n",
    "\n",
    "# Average watch time by device\n",
    "axes[0, 1].bar(device_analysis.index, device_analysis['avg_watch_time'],\n",
    "               color=PlottingUtils.COLORS['palette'][:len(device_analysis)])\n",
    "axes[0, 1].set_title('⏱️ Average Watch Time by Device')\n",
    "axes[0, 1].set_ylabel('Minutes')\n",
    "\n",
    "# Completion rate by device\n",
    "axes[1, 0].bar(device_analysis.index, device_analysis['completion_rate'],\n",
    "               color=PlottingUtils.COLORS['palette'][:len(device_analysis)])\n",
    "axes[1, 0].set_title('✅ Completion Rate by Device')\n",
    "axes[1, 0].set_ylabel('Completion Rate')\n",
    "\n",
    "# Average rating by device\n",
    "axes[1, 1].bar(device_analysis.index, device_analysis['avg_rating'],\n",
    "               color=PlottingUtils.COLORS['palette'][:len(device_analysis)])\n",
    "axes[1, 1].set_title('⭐ Average Rating by Device')\n",
    "axes[1, 1].set_ylabel('Rating (1-5)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🎯 Task 1.5: Binge-Watching Analysis\n",
    "\n",
    "**TODO:** Identify binge-worthy content (high completion rates and ratings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Find binge-worthy shows\n",
    "# Define binge-worthy as: completed = True, rating >= 4, watch_time > average\n",
    "\n",
    "# Your code here:\n",
    "avg_watch_time = netflix_df['watch_time_minutes'].mean()\n",
    "\n",
    "# Filter for potential binge-watching behavior\n",
    "binge_criteria = (\n",
    "    (netflix_df['completed'] == True) & \n",
    "    (netflix_df['rating'] >= 4) & \n",
    "    (netflix_df['watch_time_minutes'] > avg_watch_time)\n",
    ")\n",
    "\n",
    "binge_worthy = netflix_df[binge_criteria].groupby('show').agg({\n",
    "    'user_id': 'count',\n",
    "    'rating': 'mean',\n",
    "    'watch_time_minutes': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "binge_worthy.columns = ['binge_count', 'avg_rating', 'avg_watch_time']\n",
    "binge_worthy = binge_worthy.sort_values('binge_count', ascending=False).head(10)\n",
    "\n",
    "print(\"🍿 Top 10 Binge-Worthy Shows:\")\n",
    "display(binge_worthy)\n",
    "\n",
    "# Visualization\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "bars = ax.bar(range(len(binge_worthy)), binge_worthy['binge_count'],\n",
    "               color=PlottingUtils.COLORS['success'])\n",
    "ax.set_xticks(range(len(binge_worthy)))\n",
    "ax.set_xticklabels(binge_worthy.index, rotation=45, ha='right')\n",
    "ax.set_title('🍿 Most Binge-Watched Shows on Netflix', fontweight='bold', fontsize=14)\n",
    "ax.set_xlabel('Show')\n",
    "ax.set_ylabel('Number of Binge Sessions')\n",
    "\n",
    "# Add rating stars on top of bars\n",
    "for i, (bar, rating) in enumerate(zip(bars, binge_worthy['avg_rating'])):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 2,\n",
    "            f'⭐{rating:.1f}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n🎯 Most Binge-Worthy: {binge_worthy.index[0]} with {binge_worthy.iloc[0]['binge_count']:.0f} binge sessions!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ Self-Check Quiz: Netflix Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive quiz for Netflix analysis\n",
    "netflix_quiz = InteractiveQuiz(\"Netflix Analytics Check\")\n",
    "\n",
    "netflix_quiz.add_question(\n",
    "    \"What type of analysis helps identify binge-watching behavior?\",\n",
    "    [\"Time series analysis\", \"Completion rate & rating analysis\", \"Device analysis\", \"Genre analysis\"],\n",
    "    1,\n",
    "    \"Correct! High completion rates combined with high ratings indicate binge-worthy content.\"\n",
    ")\n",
    "\n",
    "netflix_quiz.add_question(\n",
    "    \"Which metric is most important for content recommendation?\",\n",
    "    [\"Watch time only\", \"Device used\", \"User ratings and completion\", \"Time of day\"],\n",
    "    2,\n",
    "    \"Excellent! User ratings and completion rates are key indicators of content satisfaction.\"\n",
    ")\n",
    "\n",
    "quiz_widget = netflix_quiz.create_quiz()\n",
    "display(quiz_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 🛍️ Exercise 2: Retail Sales Intelligence\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"figs/shopping_cart_icon.png\" width=\"200\"/>\n",
    "</div>\n",
    "\n",
    "### 🎯 Objective\n",
    "Analyze retail transaction data to optimize sales strategies, understand customer behavior, and identify revenue opportunities.\n",
    "\n",
    "### 📋 Your Tasks:\n",
    "1. Explore sales trends over time\n",
    "2. Identify best-selling products and categories\n",
    "3. Analyze the impact of promotions\n",
    "4. Segment customers based on purchasing behavior\n",
    "5. Find revenue optimization opportunities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the retail dataset\n",
    "retail_df = pd.read_csv('datasets/retail_transactions_data.csv')\n",
    "\n",
    "# Convert date to datetime\n",
    "retail_df['date'] = pd.to_datetime(retail_df['date'])\n",
    "retail_df['month'] = retail_df['date'].dt.month\n",
    "retail_df['week'] = retail_df['date'].dt.isocalendar().week\n",
    "\n",
    "print(\"🛍️ Retail Transaction Data Loaded!\")\n",
    "print(f\"📊 Dataset Shape: {retail_df.shape}\")\n",
    "print(f\"💰 Total Revenue: ${retail_df['total_amount'].sum():,.2f}\")\n",
    "print(f\"🛒 Unique Customers: {retail_df['customer_id'].nunique()}\")\n",
    "print(f\"📦 Product Categories: {retail_df['category'].nunique()}\")\n",
    "print(\"\\n📋 Sample Transactions:\")\n",
    "display(retail_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📈 Task 2.1: Sales Trends Analysis\n",
    "\n",
    "**TODO:** Analyze sales trends over time (daily, weekly, monthly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Analyze sales trends\n",
    "# Your code here:\n",
    "\n",
    "# Daily sales\n",
    "daily_sales = retail_df.groupby('date')['total_amount'].sum().reset_index()\n",
    "daily_sales.columns = ['date', 'revenue']\n",
    "\n",
    "# Weekly sales\n",
    "weekly_sales = retail_df.groupby('week')['total_amount'].sum().reset_index()\n",
    "weekly_sales.columns = ['week', 'revenue']\n",
    "\n",
    "# Monthly sales\n",
    "monthly_sales = retail_df.groupby('month')['total_amount'].sum().reset_index()\n",
    "monthly_sales.columns = ['month', 'revenue']\n",
    "\n",
    "# Create visualizations\n",
    "fig, axes = plt.subplots(3, 1, figsize=(15, 12))\n",
    "\n",
    "# Daily trend\n",
    "axes[0].plot(daily_sales['date'], daily_sales['revenue'], \n",
    "             color=PlottingUtils.COLORS['primary'], linewidth=1)\n",
    "axes[0].set_title('📈 Daily Sales Trend', fontweight='bold')\n",
    "axes[0].set_xlabel('Date')\n",
    "axes[0].set_ylabel('Revenue ($)')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Weekly trend\n",
    "axes[1].bar(weekly_sales['week'], weekly_sales['revenue'],\n",
    "            color=PlottingUtils.COLORS['success'], alpha=0.7)\n",
    "axes[1].set_title('📊 Weekly Sales Performance', fontweight='bold')\n",
    "axes[1].set_xlabel('Week Number')\n",
    "axes[1].set_ylabel('Revenue ($)')\n",
    "\n",
    "# Monthly trend\n",
    "month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "axes[2].bar(monthly_sales['month'], monthly_sales['revenue'],\n",
    "            color=PlottingUtils.COLORS['palette'][:len(monthly_sales)])\n",
    "axes[2].set_title('📅 Monthly Sales Performance', fontweight='bold')\n",
    "axes[2].set_xlabel('Month')\n",
    "axes[2].set_ylabel('Revenue ($)')\n",
    "axes[2].set_xticks(range(1, 13))\n",
    "axes[2].set_xticklabels(month_names[:len(monthly_sales)])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\n📊 Sales Summary:\")\n",
    "print(f\"Average Daily Revenue: ${daily_sales['revenue'].mean():,.2f}\")\n",
    "print(f\"Peak Day Revenue: ${daily_sales['revenue'].max():,.2f}\")\n",
    "print(f\"Best Month: {month_names[monthly_sales.loc[monthly_sales['revenue'].idxmax(), 'month'] - 1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🏆 Task 2.2: Best-Selling Products & Categories\n",
    "\n",
    "**TODO:** Identify top products and categories by revenue and quantity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Find best-selling products and categories\n",
    "# Your code here:\n",
    "\n",
    "# Category analysis\n",
    "category_analysis = retail_df.groupby('category').agg({\n",
    "    'total_amount': 'sum',\n",
    "    'quantity': 'sum',\n",
    "    'transaction_id': 'count',\n",
    "    'unit_price': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "category_analysis.columns = ['total_revenue', 'total_quantity', 'transaction_count', 'avg_price']\n",
    "category_analysis = category_analysis.sort_values('total_revenue', ascending=False)\n",
    "\n",
    "print(\"🏆 Category Performance:\")\n",
    "display(category_analysis)\n",
    "\n",
    "# Product analysis\n",
    "product_analysis = retail_df.groupby('product').agg({\n",
    "    'total_amount': 'sum',\n",
    "    'quantity': 'sum',\n",
    "    'customer_id': 'nunique'\n",
    "}).round(2)\n",
    "\n",
    "product_analysis.columns = ['revenue', 'units_sold', 'unique_customers']\n",
    "product_analysis = product_analysis.sort_values('revenue', ascending=False).head(10)\n",
    "\n",
    "print(\"\\n📦 Top 10 Products by Revenue:\")\n",
    "display(product_analysis)\n",
    "\n",
    "# Visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Category revenue\n",
    "axes[0, 0].barh(category_analysis.index[:10], category_analysis['total_revenue'][:10],\n",
    "                color=PlottingUtils.COLORS['palette'][:10])\n",
    "axes[0, 0].set_title('💰 Revenue by Category', fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Revenue ($)')\n",
    "\n",
    "# Category quantity\n",
    "axes[0, 1].barh(category_analysis.index[:10], category_analysis['total_quantity'][:10],\n",
    "                color=PlottingUtils.COLORS['palette'][:10])\n",
    "axes[0, 1].set_title('📦 Units Sold by Category', fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Quantity')\n",
    "\n",
    "# Top products\n",
    "axes[1, 0].bar(range(len(product_analysis)), product_analysis['revenue'],\n",
    "               color=PlottingUtils.COLORS['success'])\n",
    "axes[1, 0].set_title('🏆 Top 10 Products by Revenue', fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Product Rank')\n",
    "axes[1, 0].set_ylabel('Revenue ($)')\n",
    "axes[1, 0].set_xticks(range(len(product_analysis)))\n",
    "axes[1, 0].set_xticklabels(range(1, 11))\n",
    "\n",
    "# Product popularity\n",
    "axes[1, 1].scatter(product_analysis['units_sold'], product_analysis['revenue'],\n",
    "                   s=product_analysis['unique_customers']*2, alpha=0.6,\n",
    "                   color=PlottingUtils.COLORS['info'])\n",
    "axes[1, 1].set_title('📊 Product Performance Matrix', fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Units Sold')\n",
    "axes[1, 1].set_ylabel('Revenue ($)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🎯 Task 2.3: Promotion Impact Analysis\n",
    "\n",
    "**TODO:** Analyze the effectiveness of promotions on sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Analyze promotion impact\n",
    "# Your code here:\n",
    "\n",
    "# Promotion analysis\n",
    "promo_analysis = retail_df.groupby('promotion').agg({\n",
    "    'total_amount': ['mean', 'sum', 'count'],\n",
    "    'quantity': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "promo_analysis.columns = ['avg_transaction', 'total_revenue', 'transaction_count', 'avg_quantity']\n",
    "\n",
    "print(\"🎯 Promotion Impact Analysis:\")\n",
    "display(promo_analysis)\n",
    "\n",
    "# Calculate lift\n",
    "no_promo_avg = promo_analysis.loc[False, 'avg_transaction']\n",
    "promo_avg = promo_analysis.loc[True, 'avg_transaction']\n",
    "lift = ((promo_avg - no_promo_avg) / no_promo_avg) * 100\n",
    "\n",
    "print(f\"\\n📈 Promotion Lift: {lift:.1f}% increase in average transaction value\")\n",
    "\n",
    "# Category-wise promotion effectiveness\n",
    "category_promo = retail_df.groupby(['category', 'promotion'])['total_amount'].mean().unstack(fill_value=0)\n",
    "category_promo['lift'] = ((category_promo[True] - category_promo[False]) / category_promo[False] * 100).round(1)\n",
    "category_promo = category_promo.sort_values('lift', ascending=False)\n",
    "\n",
    "print(\"\\n📊 Promotion Effectiveness by Category:\")\n",
    "display(category_promo.head(10))\n",
    "\n",
    "# Visualizations\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Overall promotion impact\n",
    "promo_labels = ['No Promotion', 'With Promotion']\n",
    "axes[0].bar(promo_labels, [promo_analysis.loc[False, 'avg_transaction'], \n",
    "                           promo_analysis.loc[True, 'avg_transaction']],\n",
    "            color=[PlottingUtils.COLORS['secondary'], PlottingUtils.COLORS['success']])\n",
    "axes[0].set_title('💳 Average Transaction Value', fontweight='bold')\n",
    "axes[0].set_ylabel('Amount ($)')\n",
    "\n",
    "# Transaction volume\n",
    "axes[1].pie([promo_analysis.loc[False, 'transaction_count'], \n",
    "             promo_analysis.loc[True, 'transaction_count']],\n",
    "            labels=promo_labels, autopct='%1.1f%%',\n",
    "            colors=[PlottingUtils.COLORS['secondary'], PlottingUtils.COLORS['success']])\n",
    "axes[1].set_title('📊 Transaction Volume Distribution', fontweight='bold')\n",
    "\n",
    "# Category lift\n",
    "top_categories = category_promo.head(8)\n",
    "axes[2].barh(range(len(top_categories)), top_categories['lift'],\n",
    "             color=PlottingUtils.COLORS['palette'][:len(top_categories)])\n",
    "axes[2].set_yticks(range(len(top_categories)))\n",
    "axes[2].set_yticklabels(top_categories.index)\n",
    "axes[2].set_title('🚀 Promotion Lift by Category (%)', fontweight='bold')\n",
    "axes[2].set_xlabel('Lift %')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 👥 Task 2.4: Customer Segmentation\n",
    "\n",
    "**TODO:** Segment customers based on their purchasing behavior (RFM analysis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Perform customer segmentation\n",
    "# Your code here:\n",
    "\n",
    "# Calculate RFM metrics\n",
    "current_date = retail_df['date'].max()\n",
    "\n",
    "rfm = retail_df.groupby('customer_id').agg({\n",
    "    'date': lambda x: (current_date - x.max()).days,  # Recency\n",
    "    'transaction_id': 'count',  # Frequency\n",
    "    'total_amount': 'sum'  # Monetary\n",
    "}).reset_index()\n",
    "\n",
    "rfm.columns = ['customer_id', 'recency', 'frequency', 'monetary']\n",
    "\n",
    "# Create segments based on quantiles\n",
    "rfm['R_score'] = pd.qcut(rfm['recency'], q=3, labels=[3, 2, 1])  # Lower recency is better\n",
    "rfm['F_score'] = pd.qcut(rfm['frequency'].rank(method='first'), q=3, labels=[1, 2, 3])\n",
    "rfm['M_score'] = pd.qcut(rfm['monetary'], q=3, labels=[1, 2, 3])\n",
    "\n",
    "# Combine scores\n",
    "rfm['RFM_score'] = rfm['R_score'].astype(str) + rfm['F_score'].astype(str) + rfm['M_score'].astype(str)\n",
    "\n",
    "# Define segments\n",
    "def segment_customers(row):\n",
    "    if row['RFM_score'] == '333':\n",
    "        return 'Champions'\n",
    "    elif row['R_score'] == 3 and row['F_score'] >= 2:\n",
    "        return 'Loyal Customers'\n",
    "    elif row['R_score'] == 3 and row['F_score'] == 1:\n",
    "        return 'Potential Loyalists'\n",
    "    elif row['R_score'] == 2:\n",
    "        return 'At Risk'\n",
    "    elif row['R_score'] == 1 and row['M_score'] == 3:\n",
    "        return 'Can\\'t Lose Them'\n",
    "    else:\n",
    "        return 'Lost'\n",
    "\n",
    "rfm['segment'] = rfm.apply(segment_customers, axis=1)\n",
    "\n",
    "# Segment summary\n",
    "segment_summary = rfm.groupby('segment').agg({\n",
    "    'customer_id': 'count',\n",
    "    'recency': 'mean',\n",
    "    'frequency': 'mean',\n",
    "    'monetary': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "segment_summary.columns = ['customer_count', 'avg_recency', 'avg_frequency', 'avg_monetary']\n",
    "segment_summary = segment_summary.sort_values('avg_monetary', ascending=False)\n",
    "\n",
    "print(\"👥 Customer Segmentation Results:\")\n",
    "display(segment_summary)\n",
    "\n",
    "# Visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Segment distribution\n",
    "segment_counts = rfm['segment'].value_counts()\n",
    "axes[0, 0].pie(segment_counts.values, labels=segment_counts.index, autopct='%1.1f%%',\n",
    "               colors=PlottingUtils.COLORS['palette'][:len(segment_counts)])\n",
    "axes[0, 0].set_title('👥 Customer Segment Distribution', fontweight='bold')\n",
    "\n",
    "# Monetary by segment\n",
    "axes[0, 1].bar(segment_summary.index, segment_summary['avg_monetary'],\n",
    "               color=PlottingUtils.COLORS['palette'][:len(segment_summary)])\n",
    "axes[0, 1].set_title('💰 Average Spend by Segment', fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Segment')\n",
    "axes[0, 1].set_ylabel('Average Monetary Value ($)')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# RFM scatter\n",
    "scatter = axes[1, 0].scatter(rfm['frequency'], rfm['monetary'], \n",
    "                             c=rfm['recency'], cmap='RdYlGn_r', \n",
    "                             s=50, alpha=0.6)\n",
    "axes[1, 0].set_title('📊 RFM Analysis: Frequency vs Monetary', fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Frequency')\n",
    "axes[1, 0].set_ylabel('Monetary ($)')\n",
    "plt.colorbar(scatter, ax=axes[1, 0], label='Recency (days)')\n",
    "\n",
    "# Segment characteristics\n",
    "segment_chars = segment_summary[['avg_recency', 'avg_frequency']].head(5)\n",
    "x = np.arange(len(segment_chars))\n",
    "width = 0.35\n",
    "\n",
    "axes[1, 1].bar(x - width/2, segment_chars['avg_recency'], width, \n",
    "               label='Avg Recency', color=PlottingUtils.COLORS['info'])\n",
    "axes[1, 1].bar(x + width/2, segment_chars['avg_frequency']*10, width, \n",
    "               label='Avg Frequency (x10)', color=PlottingUtils.COLORS['success'])\n",
    "axes[1, 1].set_xlabel('Segment')\n",
    "axes[1, 1].set_xticks(x)\n",
    "axes[1, 1].set_xticklabels(segment_chars.index, rotation=45, ha='right')\n",
    "axes[1, 1].set_title('📈 Segment Characteristics', fontweight='bold')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n🎯 Key Insight: {segment_counts.index[0]} is the largest segment with {segment_counts.iloc[0]} customers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 🎵 Exercise 3: Spotify Music Discovery\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"figs/visualization-example.png\" width=\"400\"/>\n",
    "</div>\n",
    "\n",
    "### 🎯 Objective\n",
    "Analyze Spotify streaming data to understand music preferences, discover patterns in audio features, and build insights for music recommendations.\n",
    "\n",
    "### 📋 Your Tasks:\n",
    "1. Explore genre popularity and trends\n",
    "2. Analyze audio features and their relationships\n",
    "3. Identify factors affecting skip rates\n",
    "4. Build mood-based music insights\n",
    "5. Find patterns in playlist additions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Spotify dataset\n",
    "spotify_df = pd.read_csv('datasets/spotify_music_data.csv')\n",
    "\n",
    "print(\"🎵 Spotify Music Data Loaded!\")\n",
    "print(f\"📊 Dataset Shape: {spotify_df.shape}\")\n",
    "print(f\"🎤 Unique Artists: {spotify_df['artist'].nunique()}\")\n",
    "print(f\"🎸 Genres: {spotify_df['genre'].nunique()}\")\n",
    "print(f\"🎭 Moods: {spotify_df['mood'].nunique()}\")\n",
    "print(\"\\n📋 Dataset Overview:\")\n",
    "display(spotify_df.head())\n",
    "print(\"\\n📊 Audio Feature Statistics:\")\n",
    "display(spotify_df[['tempo_bpm', 'energy', 'danceability', 'valence', 'acousticness']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🎸 Task 3.1: Genre Popularity Analysis\n",
    "\n",
    "**TODO:** Analyze which genres are most popular and their characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Analyze genre popularity and characteristics\n",
    "# Your code here:\n",
    "\n",
    "genre_analysis = spotify_df.groupby('genre').agg({\n",
    "    'play_count': ['sum', 'mean'],\n",
    "    'skip_rate': 'mean',\n",
    "    'added_to_playlist': lambda x: x.sum() / len(x),\n",
    "    'energy': 'mean',\n",
    "    'danceability': 'mean',\n",
    "    'valence': 'mean'\n",
    "}).round(3)\n",
    "\n",
    "genre_analysis.columns = ['total_plays', 'avg_plays', 'avg_skip_rate', 'playlist_add_rate', \n",
    "                          'avg_energy', 'avg_danceability', 'avg_valence']\n",
    "genre_analysis = genre_analysis.sort_values('total_plays', ascending=False)\n",
    "\n",
    "print(\"🎸 Genre Performance Analysis:\")\n",
    "display(genre_analysis)\n",
    "\n",
    "# Visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Total plays by genre\n",
    "axes[0, 0].barh(genre_analysis.index[:10], genre_analysis['total_plays'][:10],\n",
    "                color=PlottingUtils.COLORS['palette'][:10])\n",
    "axes[0, 0].set_title('🎵 Total Plays by Genre', fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Total Play Count')\n",
    "\n",
    "# Skip rate by genre\n",
    "axes[0, 1].bar(genre_analysis.index[:10], genre_analysis['avg_skip_rate'][:10],\n",
    "               color=PlottingUtils.COLORS['palette'][:10])\n",
    "axes[0, 1].set_title('⏭️ Skip Rate by Genre', fontweight='bold')\n",
    "axes[0, 1].set_ylabel('Average Skip Rate')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Audio features radar chart for top 5 genres\n",
    "top_genres = genre_analysis.head(5)\n",
    "features = ['avg_energy', 'avg_danceability', 'avg_valence']\n",
    "\n",
    "x = np.arange(len(features))\n",
    "width = 0.15\n",
    "\n",
    "for i, (genre, row) in enumerate(top_genres.iterrows()):\n",
    "    axes[1, 0].bar(x + i * width, row[features], width, label=genre)\n",
    "\n",
    "axes[1, 0].set_xlabel('Audio Features')\n",
    "axes[1, 0].set_ylabel('Average Value')\n",
    "axes[1, 0].set_title('🎼 Audio Features by Top Genres', fontweight='bold')\n",
    "axes[1, 0].set_xticks(x + width * 2)\n",
    "axes[1, 0].set_xticklabels(['Energy', 'Danceability', 'Valence'])\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# Playlist addition rate\n",
    "axes[1, 1].scatter(genre_analysis['avg_plays'], genre_analysis['playlist_add_rate'],\n",
    "                   s=genre_analysis['total_plays']/1000, alpha=0.6,\n",
    "                   color=PlottingUtils.COLORS['info'])\n",
    "axes[1, 1].set_title('📋 Playlist Addition vs Popularity', fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Average Plays per Song')\n",
    "axes[1, 1].set_ylabel('Playlist Addition Rate')\n",
    "\n",
    "# Add genre labels for top 5\n",
    "for i, (genre, row) in enumerate(genre_analysis.head(5).iterrows()):\n",
    "    axes[1, 1].annotate(genre, (row['avg_plays'], row['playlist_add_rate']),\n",
    "                       xytext=(5, 5), textcoords='offset points', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🎼 Task 3.2: Audio Features Analysis\n",
    "\n",
    "**TODO:** Explore relationships between audio features and their impact on song performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Analyze audio features\n",
    "# Your code here:\n",
    "\n",
    "# Create audio feature correlation matrix\n",
    "audio_features = ['tempo_bpm', 'energy', 'danceability', 'valence', 'acousticness', \n",
    "                  'play_count', 'skip_rate']\n",
    "audio_corr = spotify_df[audio_features].corr()\n",
    "\n",
    "# Create correlation heatmap\n",
    "fig, ax = PlottingUtils.create_correlation_heatmap(\n",
    "    spotify_df[audio_features],\n",
    "    title=\"🎼 Audio Features Correlation Matrix\",\n",
    "    figsize=(10, 8)\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "# Feature impact on performance\n",
    "print(\"\\n📊 Feature Correlations with Performance Metrics:\")\n",
    "performance_corr = pd.DataFrame({\n",
    "    'Play Count Correlation': audio_corr['play_count'].drop('play_count'),\n",
    "    'Skip Rate Correlation': audio_corr['skip_rate'].drop('skip_rate')\n",
    "}).sort_values('Play Count Correlation', ascending=False)\n",
    "display(performance_corr)\n",
    "\n",
    "# Feature distributions\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "features_to_plot = ['energy', 'danceability', 'valence', 'acousticness', 'tempo_bpm']\n",
    "\n",
    "for idx, feature in enumerate(features_to_plot):\n",
    "    row = idx // 3\n",
    "    col = idx % 3\n",
    "    axes[row, col].hist(spotify_df[feature], bins=30, \n",
    "                        color=PlottingUtils.COLORS['palette'][idx], alpha=0.7)\n",
    "    axes[row, col].set_title(f'Distribution of {feature.replace(\"_\", \" \").title()}')\n",
    "    axes[row, col].set_xlabel(feature)\n",
    "    axes[row, col].set_ylabel('Frequency')\n",
    "\n",
    "# Hide empty subplot\n",
    "axes[1, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# High-performance songs analysis\n",
    "high_performers = spotify_df[spotify_df['play_count'] > spotify_df['play_count'].quantile(0.75)]\n",
    "print(f\"\\n🌟 High-Performance Songs (Top 25% by play count):\")\n",
    "print(f\"Average Energy: {high_performers['energy'].mean():.3f}\")\n",
    "print(f\"Average Danceability: {high_performers['danceability'].mean():.3f}\")\n",
    "print(f\"Average Valence: {high_performers['valence'].mean():.3f}\")\n",
    "print(f\"Average Skip Rate: {high_performers['skip_rate'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 😊 Task 3.3: Mood-Based Music Analysis\n",
    "\n",
    "**TODO:** Analyze music characteristics by mood and their listener engagement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Analyze music by mood\n",
    "# Your code here:\n",
    "\n",
    "mood_analysis = spotify_df.groupby('mood').agg({\n",
    "    'play_count': 'sum',\n",
    "    'skip_rate': 'mean',\n",
    "    'energy': 'mean',\n",
    "    'valence': 'mean',\n",
    "    'tempo_bpm': 'mean',\n",
    "    'added_to_playlist': lambda x: x.sum() / len(x)\n",
    "}).round(3)\n",
    "\n",
    "mood_analysis.columns = ['total_plays', 'avg_skip_rate', 'avg_energy', \n",
    "                         'avg_valence', 'avg_tempo', 'playlist_rate']\n",
    "mood_analysis = mood_analysis.sort_values('total_plays', ascending=False)\n",
    "\n",
    "print(\"😊 Mood-Based Music Analysis:\")\n",
    "display(mood_analysis)\n",
    "\n",
    "# Visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Mood popularity\n",
    "axes[0, 0].pie(mood_analysis['total_plays'], labels=mood_analysis.index, \n",
    "               autopct='%1.1f%%', colors=PlottingUtils.COLORS['palette'][:len(mood_analysis)])\n",
    "axes[0, 0].set_title('🎭 Music Listening by Mood', fontweight='bold')\n",
    "\n",
    "# Mood characteristics\n",
    "mood_chars = mood_analysis[['avg_energy', 'avg_valence', 'avg_tempo']].head()\n",
    "mood_chars_norm = mood_chars.div(mood_chars.max(), axis=0)  # Normalize for comparison\n",
    "\n",
    "x = np.arange(len(mood_chars))\n",
    "width = 0.25\n",
    "\n",
    "axes[0, 1].bar(x - width, mood_chars_norm['avg_energy'], width, label='Energy')\n",
    "axes[0, 1].bar(x, mood_chars_norm['avg_valence'], width, label='Valence')\n",
    "axes[0, 1].bar(x + width, mood_chars_norm['avg_tempo'], width, label='Tempo')\n",
    "axes[0, 1].set_xlabel('Mood')\n",
    "axes[0, 1].set_ylabel('Normalized Value')\n",
    "axes[0, 1].set_title('🎼 Audio Characteristics by Mood', fontweight='bold')\n",
    "axes[0, 1].set_xticks(x)\n",
    "axes[0, 1].set_xticklabels(mood_chars.index, rotation=45)\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Skip rate by mood\n",
    "axes[1, 0].barh(mood_analysis.index, mood_analysis['avg_skip_rate'],\n",
    "                color=[PlottingUtils.COLORS['success'] if rate < 0.2 else PlottingUtils.COLORS['warning'] \n",
    "                       for rate in mood_analysis['avg_skip_rate']])\n",
    "axes[1, 0].set_title('⏭️ Skip Rate by Mood', fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Average Skip Rate')\n",
    "\n",
    "# Mood vs Energy/Valence scatter\n",
    "scatter = axes[1, 1].scatter(spotify_df['energy'], spotify_df['valence'], \n",
    "                             c=pd.Categorical(spotify_df['mood']).codes, \n",
    "                             cmap='tab10', alpha=0.5, s=20)\n",
    "axes[1, 1].set_title('🎨 Energy vs Valence by Mood', fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Energy')\n",
    "axes[1, 1].set_ylabel('Valence')\n",
    "\n",
    "# Add mood labels as legend\n",
    "mood_labels = spotify_df['mood'].unique()\n",
    "handles = [plt.Line2D([0], [0], marker='o', color='w', \n",
    "                     markerfacecolor=plt.cm.tab10(i/10), markersize=8, label=mood) \n",
    "          for i, mood in enumerate(mood_labels)]\n",
    "axes[1, 1].legend(handles=handles, title='Mood', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n🎯 Most Popular Mood: {mood_analysis.index[0]} with {mood_analysis.iloc[0]['total_plays']:,} plays\")\n",
    "print(f\"🎵 Most Engaging Mood (lowest skip): {mood_analysis['avg_skip_rate'].idxmin()} ({mood_analysis['avg_skip_rate'].min():.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 🌤️ Exercise 4: Weather Pattern Analysis\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"figs/Satellite_icon.png\" width=\"200\"/>\n",
    "</div>\n",
    "\n",
    "### 🎯 Objective\n",
    "Analyze weather data to identify climate patterns, seasonal trends, and extreme weather events across different cities.\n",
    "\n",
    "### 📋 Your Tasks:\n",
    "1. Explore temperature trends over time\n",
    "2. Identify seasonal patterns\n",
    "3. Find extreme weather events\n",
    "4. Compare weather patterns across cities\n",
    "5. Analyze climate indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the weather dataset\n",
    "weather_df = pd.read_csv('datasets/weather_patterns_data.csv')\n",
    "weather_df['date'] = pd.to_datetime(weather_df['date'])\n",
    "weather_df['month'] = weather_df['date'].dt.month\n",
    "weather_df['season'] = weather_df['date'].dt.month%12 // 3 + 1\n",
    "season_map = {1: 'Winter', 2: 'Spring', 3: 'Summer', 4: 'Fall'}\n",
    "weather_df['season_name'] = weather_df['season'].map(season_map)\n",
    "\n",
    "print(\"🌤️ Weather Pattern Data Loaded!\")\n",
    "print(f\"📊 Dataset Shape: {weather_df.shape}\")\n",
    "print(f\"🌍 Cities: {weather_df['city'].unique()}\")\n",
    "print(f\"📅 Date Range: {weather_df['date'].min().date()} to {weather_df['date'].max().date()}\")\n",
    "print(\"\\n📋 Dataset Overview:\")\n",
    "display(weather_df.head())\n",
    "print(\"\\n🌡️ Temperature Statistics:\")\n",
    "display(weather_df[['temperature', 'humidity', 'precipitation', 'wind_speed']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🌡️ Task 4.1: Temperature Trends Analysis\n",
    "\n",
    "**TODO:** Analyze temperature trends over time and identify patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Analyze temperature trends\n",
    "# Your code here:\n",
    "\n",
    "# Overall temperature trends\n",
    "monthly_temp = weather_df.groupby(weather_df['date'].dt.to_period('M'))['temperature'].agg(['mean', 'min', 'max'])\n",
    "monthly_temp.index = monthly_temp.index.to_timestamp()\n",
    "\n",
    "# City-wise temperature analysis\n",
    "city_temp = weather_df.groupby('city')['temperature'].agg(['mean', 'min', 'max', 'std']).round(2)\n",
    "city_temp = city_temp.sort_values('mean', ascending=False)\n",
    "\n",
    "print(\"🌡️ Temperature Analysis by City:\")\n",
    "display(city_temp)\n",
    "\n",
    "# Visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Temperature trend over time\n",
    "axes[0, 0].plot(monthly_temp.index, monthly_temp['mean'], \n",
    "                color=PlottingUtils.COLORS['primary'], linewidth=2, label='Mean')\n",
    "axes[0, 0].fill_between(monthly_temp.index, monthly_temp['min'], monthly_temp['max'], \n",
    "                        alpha=0.3, color=PlottingUtils.COLORS['info'])\n",
    "axes[0, 0].set_title('🌡️ Temperature Trends Over Time', fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Date')\n",
    "axes[0, 0].set_ylabel('Temperature (°F)')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# City temperature comparison\n",
    "cities = city_temp.index\n",
    "x = np.arange(len(cities))\n",
    "width = 0.25\n",
    "\n",
    "axes[0, 1].bar(x - width, city_temp['min'], width, label='Min', color=PlottingUtils.COLORS['info'])\n",
    "axes[0, 1].bar(x, city_temp['mean'], width, label='Mean', color=PlottingUtils.COLORS['success'])\n",
    "axes[0, 1].bar(x + width, city_temp['max'], width, label='Max', color=PlottingUtils.COLORS['warning'])\n",
    "\n",
    "axes[0, 1].set_xlabel('City')\n",
    "axes[0, 1].set_ylabel('Temperature (°F)')\n",
    "axes[0, 1].set_title('🌍 Temperature Comparison by City', fontweight='bold')\n",
    "axes[0, 1].set_xticks(x)\n",
    "axes[0, 1].set_xticklabels(cities, rotation=45)\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Temperature distribution\n",
    "for city in weather_df['city'].unique():\n",
    "    city_data = weather_df[weather_df['city'] == city]['temperature']\n",
    "    axes[1, 0].hist(city_data, bins=30, alpha=0.5, label=city)\n",
    "\n",
    "axes[1, 0].set_title('🌡️ Temperature Distribution by City', fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Temperature (°F)')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# Temperature variability\n",
    "axes[1, 1].bar(city_temp.index, city_temp['std'], \n",
    "               color=PlottingUtils.COLORS['palette'][:len(city_temp)])\n",
    "axes[1, 1].set_title('📊 Temperature Variability (Std Dev) by City', fontweight='bold')\n",
    "axes[1, 1].set_xlabel('City')\n",
    "axes[1, 1].set_ylabel('Standard Deviation')\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n🌡️ Warmest City: {city_temp.index[0]} (Avg: {city_temp.iloc[0]['mean']}°F)\")\n",
    "print(f\"❄️ Coldest City: {city_temp.index[-1]} (Avg: {city_temp.iloc[-1]['mean']}°F)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🍂 Task 4.2: Seasonal Pattern Analysis\n",
    "\n",
    "**TODO:** Identify seasonal weather patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Analyze seasonal patterns\n",
    "# Your code here:\n",
    "\n",
    "seasonal_analysis = weather_df.groupby('season_name').agg({\n",
    "    'temperature': ['mean', 'std'],\n",
    "    'humidity': 'mean',\n",
    "    'precipitation': 'sum',\n",
    "    'wind_speed': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "seasonal_analysis.columns = ['avg_temp', 'temp_std', 'avg_humidity', \n",
    "                             'total_precip', 'avg_wind']\n",
    "\n",
    "# Reorder seasons\n",
    "season_order = ['Winter', 'Spring', 'Summer', 'Fall']\n",
    "seasonal_analysis = seasonal_analysis.reindex(season_order)\n",
    "\n",
    "print(\"🍂 Seasonal Weather Patterns:\")\n",
    "display(seasonal_analysis)\n",
    "\n",
    "# Visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Seasonal temperatures\n",
    "colors = ['#2E86AB', '#A4C3A2', '#F18F01', '#C73E1D']  # Winter, Spring, Summer, Fall colors\n",
    "axes[0, 0].bar(seasonal_analysis.index, seasonal_analysis['avg_temp'], color=colors)\n",
    "axes[0, 0].set_title('🌡️ Average Temperature by Season', fontweight='bold')\n",
    "axes[0, 0].set_ylabel('Temperature (°F)')\n",
    "\n",
    "# Seasonal precipitation\n",
    "axes[0, 1].pie(seasonal_analysis['total_precip'], labels=seasonal_analysis.index,\n",
    "               autopct='%1.1f%%', colors=colors)\n",
    "axes[0, 1].set_title('☔ Precipitation Distribution by Season', fontweight='bold')\n",
    "\n",
    "# Weather conditions by season\n",
    "season_conditions = pd.crosstab(weather_df['season_name'], weather_df['conditions'], normalize='index') * 100\n",
    "season_conditions = season_conditions.reindex(season_order)\n",
    "\n",
    "season_conditions.plot(kind='bar', stacked=True, ax=axes[1, 0], \n",
    "                       color=PlottingUtils.COLORS['palette'][:len(season_conditions.columns)])\n",
    "axes[1, 0].set_title('🌤️ Weather Conditions by Season (%)', fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Season')\n",
    "axes[1, 0].set_ylabel('Percentage')\n",
    "axes[1, 0].legend(title='Condition', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "axes[1, 0].tick_params(axis='x', rotation=0)\n",
    "\n",
    "# Monthly temperature cycle\n",
    "monthly_cycle = weather_df.groupby('month')['temperature'].mean()\n",
    "theta = np.linspace(0, 2*np.pi, 12, endpoint=False)\n",
    "r = monthly_cycle.values\n",
    "\n",
    "ax_polar = plt.subplot(2, 2, 4, projection='polar')\n",
    "bars = ax_polar.bar(theta, r, width=2*np.pi/12, bottom=30,\n",
    "                   color=plt.cm.coolwarm((r - r.min())/(r.max() - r.min())))\n",
    "ax_polar.set_theta_zero_location('N')\n",
    "ax_polar.set_theta_direction(-1)\n",
    "ax_polar.set_title('📅 Annual Temperature Cycle', fontweight='bold', pad=20)\n",
    "ax_polar.set_xticks(theta)\n",
    "ax_polar.set_xticklabels(['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
    "                          'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⛈️ Task 4.3: Extreme Weather Events\n",
    "\n",
    "**TODO:** Identify and analyze extreme weather events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Find extreme weather events\n",
    "# Your code here:\n",
    "\n",
    "# Define extreme thresholds\n",
    "temp_q95 = weather_df['temperature'].quantile(0.95)\n",
    "temp_q5 = weather_df['temperature'].quantile(0.05)\n",
    "precip_q95 = weather_df['precipitation'].quantile(0.95)\n",
    "wind_q95 = weather_df['wind_speed'].quantile(0.95)\n",
    "\n",
    "# Identify extreme events\n",
    "weather_df['extreme_heat'] = weather_df['temperature'] > temp_q95\n",
    "weather_df['extreme_cold'] = weather_df['temperature'] < temp_q5\n",
    "weather_df['heavy_rain'] = weather_df['precipitation'] > precip_q95\n",
    "weather_df['high_wind'] = weather_df['wind_speed'] > wind_q95\n",
    "\n",
    "# Count extreme events by city\n",
    "extreme_events = weather_df.groupby('city')[['extreme_heat', 'extreme_cold', \n",
    "                                             'heavy_rain', 'high_wind']].sum()\n",
    "\n",
    "print(\"⛈️ Extreme Weather Events by City:\")\n",
    "display(extreme_events)\n",
    "\n",
    "# Find most extreme records\n",
    "print(\"\\n🌡️ Most Extreme Weather Records:\")\n",
    "print(f\"Highest Temperature: {weather_df['temperature'].max()}°F on {weather_df.loc[weather_df['temperature'].idxmax(), 'date'].date()} in {weather_df.loc[weather_df['temperature'].idxmax(), 'city']}\")\n",
    "print(f\"Lowest Temperature: {weather_df['temperature'].min()}°F on {weather_df.loc[weather_df['temperature'].idxmin(), 'date'].date()} in {weather_df.loc[weather_df['temperature'].idxmin(), 'city']}\")\n",
    "print(f\"Highest Precipitation: {weather_df['precipitation'].max():.2f} inches on {weather_df.loc[weather_df['precipitation'].idxmax(), 'date'].date()}\")\n",
    "print(f\"Highest Wind Speed: {weather_df['wind_speed'].max():.1f} mph on {weather_df.loc[weather_df['wind_speed'].idxmax(), 'date'].date()}\")\n",
    "\n",
    "# Visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Extreme events by city\n",
    "extreme_events.plot(kind='bar', ax=axes[0, 0], \n",
    "                    color=[PlottingUtils.COLORS['secondary'], PlottingUtils.COLORS['info'],\n",
    "                           PlottingUtils.COLORS['primary'], PlottingUtils.COLORS['warning']])\n",
    "axes[0, 0].set_title('⛈️ Extreme Weather Events Count by City', fontweight='bold')\n",
    "axes[0, 0].set_xlabel('City')\n",
    "axes[0, 0].set_ylabel('Number of Events')\n",
    "axes[0, 0].legend(title='Event Type')\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Extreme temperature distribution\n",
    "extreme_temps = weather_df[(weather_df['extreme_heat']) | (weather_df['extreme_cold'])]\n",
    "axes[0, 1].scatter(extreme_temps['date'], extreme_temps['temperature'],\n",
    "                   c=['red' if x else 'blue' for x in extreme_temps['extreme_heat']],\n",
    "                   alpha=0.6, s=30)\n",
    "axes[0, 1].axhline(y=temp_q95, color='red', linestyle='--', alpha=0.5, label=f'Heat threshold ({temp_q95:.1f}°F)')\n",
    "axes[0, 1].axhline(y=temp_q5, color='blue', linestyle='--', alpha=0.5, label=f'Cold threshold ({temp_q5:.1f}°F)')\n",
    "axes[0, 1].set_title('🌡️ Extreme Temperature Events Over Time', fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Date')\n",
    "axes[0, 1].set_ylabel('Temperature (°F)')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# UV Index analysis\n",
    "uv_analysis = weather_df.groupby('city')['uv_index'].agg(['mean', 'max'])\n",
    "axes[1, 0].bar(uv_analysis.index, uv_analysis['mean'], \n",
    "               color=PlottingUtils.COLORS['palette'][:len(uv_analysis)], \n",
    "               label='Average')\n",
    "axes[1, 0].scatter(uv_analysis.index, uv_analysis['max'], \n",
    "                   color='red', s=100, zorder=5, label='Maximum')\n",
    "axes[1, 0].set_title('☀️ UV Index by City', fontweight='bold')\n",
    "axes[1, 0].set_ylabel('UV Index')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Extreme event timeline\n",
    "extreme_timeline = weather_df[['date', 'extreme_heat', 'extreme_cold', 'heavy_rain', 'high_wind']].copy()\n",
    "extreme_timeline['any_extreme'] = extreme_timeline[['extreme_heat', 'extreme_cold', 'heavy_rain', 'high_wind']].any(axis=1)\n",
    "monthly_extremes = extreme_timeline.groupby(extreme_timeline['date'].dt.to_period('M'))['any_extreme'].sum()\n",
    "monthly_extremes.index = monthly_extremes.index.to_timestamp()\n",
    "\n",
    "axes[1, 1].plot(monthly_extremes.index, monthly_extremes.values, \n",
    "                color=PlottingUtils.COLORS['secondary'], linewidth=2)\n",
    "axes[1, 1].fill_between(monthly_extremes.index, monthly_extremes.values, \n",
    "                        alpha=0.3, color=PlottingUtils.COLORS['secondary'])\n",
    "axes[1, 1].set_title('📈 Extreme Weather Events Timeline', fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Date')\n",
    "axes[1, 1].set_ylabel('Number of Extreme Events')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 📱 Exercise 5: Social Media Engagement\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"figs/brain_intertwined_with_circuitry.png\" width=\"300\"/>\n",
    "</div>\n",
    "\n",
    "### 🎯 Objective\n",
    "Analyze social media data to understand engagement patterns, viral content characteristics, and platform-specific behaviors.\n",
    "\n",
    "### 📋 Your Tasks:\n",
    "1. Compare engagement across platforms\n",
    "2. Identify viral content characteristics\n",
    "3. Analyze sentiment and its impact\n",
    "4. Find engagement rate drivers\n",
    "5. Identify influencer patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the social media dataset\n",
    "social_df = pd.read_csv('datasets/social_media_data.csv')\n",
    "\n",
    "print(\"📱 Social Media Data Loaded!\")\n",
    "print(f\"📊 Dataset Shape: {social_df.shape}\")\n",
    "print(f\"📱 Platforms: {social_df['platform'].unique()}\")\n",
    "print(f\"📝 Topics: {social_df['topic'].unique()}\")\n",
    "print(f\"✅ Verified Accounts: {social_df['verified_account'].sum()} ({social_df['verified_account'].mean():.1%})\")\n",
    "print(\"\\n📋 Dataset Overview:\")\n",
    "display(social_df.head())\n",
    "print(\"\\n📊 Engagement Statistics:\")\n",
    "display(social_df[['likes', 'shares', 'comments', 'engagement_rate']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📱 Task 5.1: Platform Comparison\n",
    "\n",
    "**TODO:** Compare engagement metrics across different social media platforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compare platforms\n",
    "# Your code here:\n",
    "\n",
    "platform_analysis = social_df.groupby('platform').agg({\n",
    "    'likes': 'mean',\n",
    "    'shares': 'mean',\n",
    "    'comments': 'mean',\n",
    "    'engagement_rate': 'mean',\n",
    "    'text_length': 'mean',\n",
    "    'hashtags': 'mean',\n",
    "    'post_id': 'count'\n",
    "}).round(2)\n",
    "\n",
    "platform_analysis.columns = ['avg_likes', 'avg_shares', 'avg_comments', \n",
    "                             'avg_engagement', 'avg_text_length', 'avg_hashtags', 'post_count']\n",
    "platform_analysis = platform_analysis.sort_values('avg_engagement', ascending=False)\n",
    "\n",
    "print(\"📱 Platform Performance Analysis:\")\n",
    "display(platform_analysis)\n",
    "\n",
    "# Visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Engagement by platform\n",
    "axes[0, 0].bar(platform_analysis.index, platform_analysis['avg_engagement'],\n",
    "               color=PlottingUtils.COLORS['palette'][:len(platform_analysis)])\n",
    "axes[0, 0].set_title('📊 Average Engagement Rate by Platform', fontweight='bold')\n",
    "axes[0, 0].set_ylabel('Engagement Rate')\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Interaction types by platform\n",
    "interaction_cols = ['avg_likes', 'avg_shares', 'avg_comments']\n",
    "x = np.arange(len(platform_analysis))\n",
    "width = 0.25\n",
    "\n",
    "axes[0, 1].bar(x - width, platform_analysis['avg_likes'], width, label='Likes')\n",
    "axes[0, 1].bar(x, platform_analysis['avg_shares'], width, label='Shares')\n",
    "axes[0, 1].bar(x + width, platform_analysis['avg_comments'], width, label='Comments')\n",
    "axes[0, 1].set_xlabel('Platform')\n",
    "axes[0, 1].set_ylabel('Average Count')\n",
    "axes[0, 1].set_title('💬 Interaction Types by Platform', fontweight='bold')\n",
    "axes[0, 1].set_xticks(x)\n",
    "axes[0, 1].set_xticklabels(platform_analysis.index, rotation=45)\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Platform post distribution\n",
    "axes[1, 0].pie(platform_analysis['post_count'], labels=platform_analysis.index,\n",
    "               autopct='%1.1f%%', colors=PlottingUtils.COLORS['palette'][:len(platform_analysis)])\n",
    "axes[1, 0].set_title('📱 Post Distribution Across Platforms', fontweight='bold')\n",
    "\n",
    "# Content characteristics by platform\n",
    "axes[1, 1].scatter(platform_analysis['avg_text_length'], platform_analysis['avg_hashtags'],\n",
    "                   s=platform_analysis['avg_engagement']*1000, alpha=0.6,\n",
    "                   c=range(len(platform_analysis)), cmap='viridis')\n",
    "for i, platform in enumerate(platform_analysis.index):\n",
    "    axes[1, 1].annotate(platform, \n",
    "                       (platform_analysis.iloc[i]['avg_text_length'], \n",
    "                        platform_analysis.iloc[i]['avg_hashtags']),\n",
    "                       xytext=(5, 5), textcoords='offset points', fontsize=9)\n",
    "axes[1, 1].set_title('📝 Content Characteristics by Platform', fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Average Text Length')\n",
    "axes[1, 1].set_ylabel('Average Hashtags')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🚀 Task 5.2: Viral Content Analysis\n",
    "\n",
    "**TODO:** Identify characteristics of viral content (high engagement posts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Analyze viral content\n",
    "# Your code here:\n",
    "\n",
    "# Define viral as top 10% engagement rate\n",
    "viral_threshold = social_df['engagement_rate'].quantile(0.9)\n",
    "social_df['is_viral'] = social_df['engagement_rate'] > viral_threshold\n",
    "\n",
    "print(f\"🚀 Viral Threshold: {viral_threshold:.3f} engagement rate\")\n",
    "print(f\"📊 Viral Posts: {social_df['is_viral'].sum()} ({social_df['is_viral'].mean():.1%})\")\n",
    "\n",
    "# Compare viral vs non-viral\n",
    "viral_comparison = social_df.groupby('is_viral').agg({\n",
    "    'likes': 'mean',\n",
    "    'shares': 'mean',\n",
    "    'comments': 'mean',\n",
    "    'text_length': 'mean',\n",
    "    'hashtags': 'mean',\n",
    "    'mentions': 'mean',\n",
    "    'verified_account': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "viral_comparison.index = ['Non-Viral', 'Viral']\n",
    "print(\"\\n🔥 Viral vs Non-Viral Content:\")\n",
    "display(viral_comparison.T)\n",
    "\n",
    "# Topic analysis for viral content\n",
    "viral_topics = pd.crosstab(social_df['topic'], social_df['is_viral'], normalize='index') * 100\n",
    "viral_topics = viral_topics.sort_values(True, ascending=False)\n",
    "\n",
    "print(\"\\n📝 Viral Rate by Topic:\")\n",
    "display(viral_topics)\n",
    "\n",
    "# Visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Viral characteristics comparison\n",
    "comparison_metrics = ['likes', 'shares', 'comments', 'hashtags']\n",
    "viral_means = [viral_comparison.loc['Viral', m] for m in comparison_metrics]\n",
    "non_viral_means = [viral_comparison.loc['Non-Viral', m] for m in comparison_metrics]\n",
    "\n",
    "x = np.arange(len(comparison_metrics))\n",
    "width = 0.35\n",
    "\n",
    "axes[0, 0].bar(x - width/2, non_viral_means, width, label='Non-Viral', color=PlottingUtils.COLORS['secondary'])\n",
    "axes[0, 0].bar(x + width/2, viral_means, width, label='Viral', color=PlottingUtils.COLORS['success'])\n",
    "axes[0, 0].set_xlabel('Metric')\n",
    "axes[0, 0].set_ylabel('Average Value')\n",
    "axes[0, 0].set_title('🚀 Viral vs Non-Viral Content Metrics', fontweight='bold')\n",
    "axes[0, 0].set_xticks(x)\n",
    "axes[0, 0].set_xticklabels(comparison_metrics)\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Viral rate by topic\n",
    "axes[0, 1].barh(viral_topics.index, viral_topics[True],\n",
    "                color=PlottingUtils.COLORS['palette'][:len(viral_topics)])\n",
    "axes[0, 1].set_title('🔥 Viral Rate by Topic (%)', fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Viral Percentage')\n",
    "\n",
    "# Text length distribution\n",
    "axes[1, 0].hist(social_df[~social_df['is_viral']]['text_length'], bins=30, \n",
    "                alpha=0.5, label='Non-Viral', color=PlottingUtils.COLORS['secondary'])\n",
    "axes[1, 0].hist(social_df[social_df['is_viral']]['text_length'], bins=30, \n",
    "                alpha=0.5, label='Viral', color=PlottingUtils.COLORS['success'])\n",
    "axes[1, 0].set_title('📝 Text Length Distribution', fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Text Length (characters)')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# Engagement scatter\n",
    "colors = ['red' if v else 'blue' for v in social_df['is_viral']]\n",
    "axes[1, 1].scatter(social_df['hashtags'], social_df['engagement_rate'],\n",
    "                   c=colors, alpha=0.3, s=20)\n",
    "axes[1, 1].axhline(y=viral_threshold, color='green', linestyle='--', \n",
    "                   label=f'Viral Threshold ({viral_threshold:.3f})')\n",
    "axes[1, 1].set_title('📊 Hashtags vs Engagement Rate', fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Number of Hashtags')\n",
    "axes[1, 1].set_ylabel('Engagement Rate')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n🎯 Key Insight: Viral posts have {(viral_means[1]/non_viral_means[1] - 1)*100:.1f}% more shares than non-viral posts!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 😊 Task 5.3: Sentiment Analysis Impact\n",
    "\n",
    "**TODO:** Analyze how sentiment affects engagement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Analyze sentiment impact\n",
    "# Your code here:\n",
    "\n",
    "sentiment_analysis = social_df.groupby('sentiment').agg({\n",
    "    'engagement_rate': 'mean',\n",
    "    'likes': 'mean',\n",
    "    'shares': 'mean',\n",
    "    'comments': 'mean',\n",
    "    'post_id': 'count'\n",
    "}).round(3)\n",
    "\n",
    "sentiment_analysis.columns = ['avg_engagement', 'avg_likes', 'avg_shares', 'avg_comments', 'post_count']\n",
    "sentiment_analysis = sentiment_analysis.sort_values('avg_engagement', ascending=False)\n",
    "\n",
    "print(\"😊 Sentiment Impact on Engagement:\")\n",
    "display(sentiment_analysis)\n",
    "\n",
    "# Platform-sentiment analysis\n",
    "platform_sentiment = pd.crosstab(social_df['platform'], social_df['sentiment'], \n",
    "                                 values=social_df['engagement_rate'], aggfunc='mean').round(3)\n",
    "\n",
    "print(\"\\n📱 Engagement by Platform and Sentiment:\")\n",
    "display(platform_sentiment)\n",
    "\n",
    "# Visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Sentiment distribution\n",
    "sentiment_colors = {'Positive': PlottingUtils.COLORS['success'], \n",
    "                   'Negative': PlottingUtils.COLORS['secondary'], \n",
    "                   'Neutral': PlottingUtils.COLORS['info']}\n",
    "colors = [sentiment_colors.get(s, PlottingUtils.COLORS['primary']) for s in sentiment_analysis.index]\n",
    "\n",
    "axes[0, 0].pie(sentiment_analysis['post_count'], labels=sentiment_analysis.index,\n",
    "               autopct='%1.1f%%', colors=colors)\n",
    "axes[0, 0].set_title('😊 Sentiment Distribution', fontweight='bold')\n",
    "\n",
    "# Engagement by sentiment\n",
    "axes[0, 1].bar(sentiment_analysis.index, sentiment_analysis['avg_engagement'], color=colors)\n",
    "axes[0, 1].set_title('📊 Engagement Rate by Sentiment', fontweight='bold')\n",
    "axes[0, 1].set_ylabel('Average Engagement Rate')\n",
    "\n",
    "# Platform-sentiment heatmap\n",
    "im = axes[1, 0].imshow(platform_sentiment.values, cmap='RdYlGn', aspect='auto')\n",
    "axes[1, 0].set_xticks(np.arange(len(platform_sentiment.columns)))\n",
    "axes[1, 0].set_yticks(np.arange(len(platform_sentiment.index)))\n",
    "axes[1, 0].set_xticklabels(platform_sentiment.columns)\n",
    "axes[1, 0].set_yticklabels(platform_sentiment.index)\n",
    "\n",
    "# Add values to heatmap\n",
    "for i in range(len(platform_sentiment.index)):\n",
    "    for j in range(len(platform_sentiment.columns)):\n",
    "        axes[1, 0].text(j, i, f'{platform_sentiment.iloc[i, j]:.3f}',\n",
    "                       ha='center', va='center', color='white', fontweight='bold')\n",
    "\n",
    "axes[1, 0].set_title('🔥 Engagement Heatmap: Platform vs Sentiment', fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Sentiment')\n",
    "axes[1, 0].set_ylabel('Platform')\n",
    "\n",
    "# Interaction types by sentiment\n",
    "interaction_metrics = ['avg_likes', 'avg_shares', 'avg_comments']\n",
    "sentiment_interactions = sentiment_analysis[interaction_metrics]\n",
    "\n",
    "sentiment_interactions.plot(kind='bar', ax=axes[1, 1], \n",
    "                           color=PlottingUtils.COLORS['palette'][:3])\n",
    "axes[1, 1].set_title('💬 Interaction Types by Sentiment', fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Sentiment')\n",
    "axes[1, 1].set_ylabel('Average Count')\n",
    "axes[1, 1].legend(title='Interaction Type')\n",
    "axes[1, 1].tick_params(axis='x', rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "best_sentiment = sentiment_analysis.index[0]\n",
    "print(f\"\\n🎯 Key Insight: {best_sentiment} sentiment drives highest engagement ({sentiment_analysis.iloc[0]['avg_engagement']:.3f})!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 🏆 Challenge Section: Cross-Dataset Analysis\n",
    "\n",
    "### 🎯 Advanced Challenge\n",
    "Now that you've analyzed each dataset individually, try combining insights across datasets for deeper analysis!\n",
    "\n",
    "**Ideas to explore:**\n",
    "1. **Weather & Retail**: How does weather affect shopping patterns?\n",
    "2. **Social Media & Netflix**: Content trends across platforms\n",
    "3. **Spotify & Social Media**: Music trends and social engagement\n",
    "4. **Weather & Social Media**: Does weather affect social media mood?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge Example: Weather impact on entertainment consumption\n",
    "print(\"🏆 CHALLENGE: Cross-Dataset Analysis\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\nExample: Analyzing patterns across different datasets...\\n\")\n",
    "\n",
    "# Example: Compare seasonal patterns\n",
    "# Weather has clear seasons, let's see if other activities follow similar patterns\n",
    "\n",
    "# Add month to datasets for comparison\n",
    "retail_df['month'] = pd.to_datetime(retail_df['date']).dt.month\n",
    "\n",
    "# Monthly patterns comparison\n",
    "weather_monthly = weather_df.groupby('month')['temperature'].mean()\n",
    "retail_monthly = retail_df.groupby('month')['total_amount'].sum()\n",
    "\n",
    "# Normalize for comparison\n",
    "weather_norm = (weather_monthly - weather_monthly.min()) / (weather_monthly.max() - weather_monthly.min())\n",
    "retail_norm = (retail_monthly - retail_monthly.min()) / (retail_monthly.max() - retail_monthly.min())\n",
    "\n",
    "# Visualization\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "x = range(len(weather_norm))\n",
    "\n",
    "ax.plot(x, weather_norm, marker='o', label='Temperature (normalized)', linewidth=2)\n",
    "ax.plot(x, retail_norm[:len(weather_norm)], marker='s', label='Retail Sales (normalized)', linewidth=2)\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(months[:len(weather_norm)])\n",
    "ax.set_title('🌡️💰 Seasonal Patterns: Temperature vs Retail Sales', fontweight='bold', fontsize=14)\n",
    "ax.set_xlabel('Month')\n",
    "ax.set_ylabel('Normalized Value (0-1)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate correlation\n",
    "correlation = np.corrcoef(weather_norm, retail_norm[:len(weather_norm)])[0, 1]\n",
    "print(f\"\\n📊 Correlation between temperature and retail sales: {correlation:.3f}\")\n",
    "\n",
    "print(\"\\n💡 YOUR TURN: Try creating your own cross-dataset analysis!\")\n",
    "print(\"Suggestions:\")\n",
    "print(\"- Compare Netflix viewing patterns with weather (indoor activity)\")\n",
    "print(\"- Analyze if social media sentiment varies by day of week (from retail data)\")\n",
    "print(\"- See if music energy levels correlate with time patterns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Your cross-dataset analysis\n",
    "# Write your creative analysis here!\n",
    "\n",
    "# Your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 🎉 Congratulations! Summary & Portfolio\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"figs/Data_Science_VD.png\" width=\"400\"/>\n",
    "</div>\n",
    "\n",
    "### 🏆 What You've Accomplished\n",
    "\n",
    "You've just completed **5 comprehensive data science projects** using real-world datasets!\n",
    "\n",
    "#### 📊 Your Data Science Portfolio:\n",
    "\n",
    "1. **Netflix Analytics** 🎬\n",
    "   - Analyzed viewing patterns and binge-watching behavior\n",
    "   - Skills: Time series analysis, user behavior analytics\n",
    "\n",
    "2. **Retail Intelligence** 🛍️\n",
    "   - Optimized sales strategies and customer segmentation\n",
    "   - Skills: RFM analysis, revenue optimization, promotion analysis\n",
    "\n",
    "3. **Spotify Music Discovery** 🎵\n",
    "   - Explored audio features and recommendation patterns\n",
    "   - Skills: Feature correlation, pattern recognition\n",
    "\n",
    "4. **Weather Pattern Analysis** 🌤️\n",
    "   - Identified climate trends and extreme events\n",
    "   - Skills: Time series, anomaly detection, seasonal analysis\n",
    "\n",
    "5. **Social Media Engagement** 📱\n",
    "   - Decoded viral content and engagement drivers\n",
    "   - Skills: Sentiment analysis, viral prediction, platform analytics\n",
    "\n",
    "### 🛠️ Skills You've Developed:\n",
    "\n",
    "✅ **Data Exploration & Cleaning**  \n",
    "✅ **Statistical Analysis**  \n",
    "✅ **Data Visualization**  \n",
    "✅ **Pattern Recognition**  \n",
    "✅ **Business Insights Generation**  \n",
    "✅ **Storytelling with Data**  \n",
    "✅ **Cross-functional Analysis**  \n",
    "\n",
    "### 📈 Your Analytics Metrics:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate your accomplishments\n",
    "total_rows_analyzed = sum([\n",
    "    len(netflix_df),\n",
    "    len(retail_df),\n",
    "    len(spotify_df),\n",
    "    len(weather_df),\n",
    "    len(social_df)\n",
    "])\n",
    "\n",
    "datasets_explored = 5\n",
    "visualizations_created = 20  # Approximate based on exercises\n",
    "insights_generated = 25  # Approximate\n",
    "\n",
    "print(\"📊 YOUR DATA SCIENCE ACHIEVEMENTS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"📈 Total Rows Analyzed: {total_rows_analyzed:,}\")\n",
    "print(f\"📁 Datasets Explored: {datasets_explored}\")\n",
    "print(f\"📊 Visualizations Created: ~{visualizations_created}\")\n",
    "print(f\"💡 Insights Generated: ~{insights_generated}\")\n",
    "print(f\"🏆 Skill Level: Data Science Practitioner\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Create a completion certificate visualization\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "ax.text(0.5, 0.9, '🏆 Certificate of Completion 🏆', \n",
    "        fontsize=24, fontweight='bold', ha='center')\n",
    "ax.text(0.5, 0.75, 'Data Science Bootcamp Exercises', \n",
    "        fontsize=18, ha='center')\n",
    "ax.text(0.5, 0.6, f'Successfully Analyzed {total_rows_analyzed:,} Data Points', \n",
    "        fontsize=14, ha='center')\n",
    "ax.text(0.5, 0.5, f'Across {datasets_explored} Real-World Datasets', \n",
    "        fontsize=14, ha='center')\n",
    "\n",
    "skills = ['Netflix Analytics ✓', 'Retail Intelligence ✓', 'Music Discovery ✓', \n",
    "          'Weather Analysis ✓', 'Social Media Analytics ✓']\n",
    "for i, skill in enumerate(skills):\n",
    "    ax.text(0.5, 0.35 - i*0.05, skill, fontsize=12, ha='center', color='green')\n",
    "\n",
    "ax.text(0.5, 0.05, f'Date: {datetime.now().strftime(\"%B %d, %Y\")}', \n",
    "        fontsize=10, ha='center', style='italic')\n",
    "\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.axis('off')\n",
    "\n",
    "# Add border\n",
    "rect = plt.Rectangle((0.05, 0.02), 0.9, 0.96, fill=False, \n",
    "                     edgecolor='gold', linewidth=3)\n",
    "ax.add_patch(rect)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🚀 Next Steps\n",
    "\n",
    "You're now ready to:\n",
    "\n",
    "1. **Build Your Portfolio** 💼\n",
    "   - Share your analyses on GitHub\n",
    "   - Create a data science blog\n",
    "   - Showcase projects to employers\n",
    "\n",
    "2. **Advance Your Skills** 📚\n",
    "   - Try machine learning models on these datasets\n",
    "   - Build interactive dashboards\n",
    "   - Combine multiple datasets for deeper insights\n",
    "\n",
    "3. **Real-World Applications** 🌍\n",
    "   - Apply these techniques to your own data\n",
    "   - Solve business problems\n",
    "   - Contribute to open-source projects\n",
    "\n",
    "### 💬 Final Interactive Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final knowledge check\n",
    "final_quiz = InteractiveQuiz(\"Data Science Mastery Check\")\n",
    "\n",
    "final_quiz.add_question(\n",
    "    \"Which analysis technique helps identify customer segments?\",\n",
    "    [\"Time series analysis\", \"RFM analysis\", \"Correlation analysis\", \"Sentiment analysis\"],\n",
    "    1,\n",
    "    \"Excellent! RFM (Recency, Frequency, Monetary) analysis is perfect for customer segmentation.\"\n",
    ")\n",
    "\n",
    "final_quiz.add_question(\n",
    "    \"What's the best way to identify viral content characteristics?\",\n",
    "    [\"Look at timestamps\", \"Compare high vs low engagement posts\", \"Count hashtags\", \"Check platform\"],\n",
    "    1,\n",
    "    \"Perfect! Comparing characteristics of high vs low engagement content reveals viral patterns.\"\n",
    ")\n",
    "\n",
    "final_quiz.add_question(\n",
    "    \"Which skill is MOST important for a data scientist?\",\n",
    "    [\"Programming only\", \"Statistics only\", \"Visualization only\", \"Curiosity and problem-solving\"],\n",
    "    3,\n",
    "    \"Absolutely right! Curiosity and problem-solving drive all great data science work!\"\n",
    ")\n",
    "\n",
    "quiz_widget = final_quiz.create_quiz()\n",
    "display(quiz_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<div style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 30px; border-radius: 10px; margin: 20px 0; text-align: center;\">\n",
    "    <h2>🎊 You Did It!</h2>\n",
    "    <p style=\"font-size: 18px;\">You've completed the Data Science Bootcamp Exercises!</p>\n",
    "    <p style=\"font-size: 16px;\">You're not just learning data science — you're becoming a data scientist!</p>\n",
    "    <br>\n",
    "    <p style=\"font-size: 20px; font-weight: bold;\">Welcome to the data-driven future! 🚀</p>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "### 📝 Notes Section\n",
    "Use this space to write your own notes, ideas, and insights from the exercises:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your notes and observations\n",
    "my_notes = \"\"\"\n",
    "Key Learnings:\n",
    "1. \n",
    "2. \n",
    "3. \n",
    "\n",
    "Ideas for Future Projects:\n",
    "- \n",
    "- \n",
    "- \n",
    "\n",
    "Questions to Explore:\n",
    "- \n",
    "- \n",
    "\"\"\"\n",
    "\n",
    "print(my_notes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
